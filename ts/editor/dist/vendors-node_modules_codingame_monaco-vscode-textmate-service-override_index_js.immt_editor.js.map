{"version":3,"file":"vendors-node_modules_codingame_monaco-vscode-textmate-service-override_index_js.immt_editor.js","mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAAwC;AACgG;;;;;;;;;;;;;;;;;;;;;;;;;;ACDrC;AACqC;AACA;AAC5C;AACyC;AAC1B;AACxB;AACX;AACzB;AACgD;AACQ;;AAEvG,0BAA0B,4JAAqD;AAC/E,6DAAc;AACd;AACA;AACA,CAAC;AACD,sFAAoC;AACpC;AACA,aAAa,qHAAiB;AAC9B;AACA;AACA,QAAQ,6GAAkB,KAAK,kJAA4B;AAC3D,KAAK;AACL,CAAC;AACD;AACA;AACA,WAAW,2FAAoB;AAC/B,WAAW,kJAA4B,mBAAmB,sGAAc,CAAC,8IAA2B;AACpG;AACA;;AAEyC;;;;;;;;;;;;;;;;;;;;AChCgB;AAC0B;AACpC;AACiB;AACrB;;AAE3C;AACA,IAAI,8EAAU,CAAC,mEAAK;AACpB;AACA;AACA,8BAA8B,eAAe,GAAG,qBAAqB;AACrE,mCAAmC,iFAAe;AAClD,4BAA4B,sBAAsB,GAAG,eAAe;AACpE,eAAe,4EAAU;AACzB;;AAEoC;;;;;;;;;;;;;;;;;;;AChB8C;;AAElF;AACA;AACA;AACA,wCAAwC,8EAAS,gBAAgB,iFAAgB;AACjF;AACA;AACA,4CAA4C,QAAQ;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,YAAY,KAAK,YAAY,QAAQ,gBAAgB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4F;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/DxB;AACvB;AACD;AACsC;AACjB;AACd;AACkC;AACX;AACA;AACR;AAC4B;AAC4B;AACd;AACd;;AAE9F,gDAAgD,8EAAU;AAC1D,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yGAAsB;AACnD,+BAA+B,2HAAqB;AACpD,uBAAuB,mGAAY;AACnC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,uBAAuB,gGAAO;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qIAAgC;AACrD;AACA;AACA;AACA;AACA,oEAAoE,oFAAS;AAC7E,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,2EAA0B;AAC3E,4BAA4B,qIAAgC;AAC5D;AACA,gDAAgD,sBAAsB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mBAAmB;AACvD;AACA;AACA;AACA;AACA;AACA,6CAA6C,2EAA0B;AACvE;AACA,oBAAoB,+BAA+B,QAAQ,gOAAyB;AACpF;AACA;AACA;AACA;AACA;AACA,4BAA4B,0BAA0B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA,iBAAiB,0DAAS,sBAAsB,gEAAe;AAC/D;AACA;AACA,QAAQ,wFAAQ;AAChB;AACA;AACA;AACA,gCAAgC,4EAAK;AACrC;;AAE6C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7J4B;AACc;AACJ;AACpC;AACQ;AAC8B;AACwB;AACN;AACoC;AACjC;AACT;AAC7B;AACuB;AACN;;AAErF;AACA;AACA,aAAa;AACb,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mFAAe;AAC3C;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA,yCAAyC,qGAAiC;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oFAAY;AACnC;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,0FAA0F;AAC1F,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,iFAAe,CAAC;AAC3D;AACA,iCAAiC,kBAAkB;AACnD;AACA;AACA,kCAAkC,4EAAU;AAC5C;AACA,sCAAsC,oGAAe;AACrD,QAAQ,8EAAkB;AAC1B;AACA,iCAAiC,iEAAG;AACpC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,8EAAU;AACxF,MAAM,2EAAO,IAAI,qJAA+B;AAChD,MAAM,2EAAO,IAAI,uHAAqB;AACtC,MAAM,2EAAO,IAAI,+FAAgB;AACjC,MAAM,2EAAO,IAAI,iHAAmB;AACpC,MAAM,2EAAO,IAAI,oHAAoB;AACrC,MAAM,2EAAO,IAAI,4GAAiB;AAClC;AACA;AACA,kCAAkC,mFAAe;AACjD,+CAA+C,mFAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAE8C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrL2B;AACV;AACM;AACR;AACF;AACa;AACa;AACF;AACvC;AACqB;AACA;AACd;AACyC;AAC9B;AACqB;AACrB;AAC2C;AACpB;AACyB;AAC9D;AAC6D;AAC8B;AACtC;AACtB;AAC2B;AACZ;AACG;AACgC;AAC9B;AACU;AACO;AACrB;AACG;AACuB;;AAEzH;AACA,4EAA4E,8EAAU;AACtF,aAAa;AACb,aAAa,uCAAuC;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,mFAAe;AAC9D;AACA;AACA,6FAA6F,8HAAkC;AAC/H;AACA,6BAA6B,mFAAgB;AAC7C;AACA,QAAQ,6GAAgB;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,8FAAuB;AACtF;AACA,0DAA0D,2FAAoB;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2FAAoB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iFAAQ;AACxC;AACA;AACA;AACA,iDAAiD,SAAS;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,+DAAQ;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+DAAQ;AACpC,aAAa;AACb;AACA,+BAA+B,+DAAQ;AACvC,iBAAiB;AACjB;AACA;AACA;AACA,mCAAmC,+DAAQ;AAC3C,qBAAqB;AACrB;AACA,8DAA8D;AAC9D;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,gOAAyB;AAC9F;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,sCAAsC,0EAAgB;AACtD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,6GAA2B;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,sBAAsB,uHAAgC;AACtD;AACA;AACA;AACA,+CAA+C,sFAA4B;AAC3E;AACA;AACA,YAAY,sFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA,eAAe,2EAAM;AACrB;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA,yBAAyB,6HAA4B;AACrD;AACA,QAAQ,2FAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,UAAU;AAC1B;AACA;AACA;AACA;AACA;AACA,mEAAmE,mOAA0B;AAC7F;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,YAAY,yEAAK;AACjB,yCAAyC,kEAAwB;AACjE;AACA;AACA;AACA;AACA,+CAA+C,4EAAU,iBAAiB,iFAAe,CAAC;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iEAAiE,8EAAU;AAC3E,OAAO,2EAAO,IAAI,gGAAgB;AAClC,OAAO,2EAAO,IAAI,oIAAsB;AACxC,OAAO,2EAAO,IAAI,sJAA+B;AACjD,OAAO,2EAAO,IAAI,qHAAoB;AACtC,OAAO,2EAAO,IAAI,0FAAW;AAC7B,OAAO,2EAAO,IAAI,wHAAqB;AACvC,OAAO,2EAAO,IAAI,yGAAgB;AAClC,OAAO,2EAAO,IAAI,4IAA4B;AAC9C,OAAO,2EAAO,IAAI,gHAAqB;AACvC,OAAO,2EAAO,IAAI,4GAAiB;AACnC;AACA;AACA;AACA,2CAA2C,SAAS;AACpD,uBAAuB,qEAAK;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,QAAQ;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAQ;AAClC;AACA,+CAA+C,EAAE,6BAA6B,EAAE;AAChF,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAQ;AAClC;AACA,8CAA8C,EAAE,8BAA8B,EAAE;AAChF,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAQ;AAClC;AACA,8CAA8C,EAAE,yBAAyB,EAAE;AAC3E,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAQ;AAClC;AACA,4CAA4C,EAAE,uEAAuE,EAAE;AACvH,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA,qCAAqC,6EAAQ;AAC7C,0BAA0B,+DAAQ;AAClC;AACA,4CAA4C,EAAE,yFAAyF,EAAE;AACzI,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA,8BAA8B,6EAAQ;AACtC,0BAA0B,+DAAQ;AAClC;AACA,4CAA4C,EAAE,oFAAoF,EAAE;AACpI,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA,4BAA4B,iFAAQ;AACpC,SAAS,wFAAe;AACxB,yBAAyB,+DAAQ;AACjC;AACA,oCAAoC,EAAE,SAAS,EAAE,6CAA6C,EAAE;AAChG,YAAY,6GAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2GAAmB;AAC9B,0CAA0C,gCAAgC;AAC1E;AACA;AACA,KAAK,8CAA8C,gCAAgC;AACnF;;AAEuC;;;;;;;;;;;;;;;;;;;;;AC/ckC;AACzB;AAC8D;AACgC;AAC7C;AACI;;AAErG,oCAAoC,kIAA8B;AAClE,0BAA0B,wHAAkB;AAC5C;AACA;AACA,uBAAuB,8DAAQ;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,8DAAQ;AAC3C,6BAA6B,wHAAwB;AACrD,2CAA2C,8DAAQ;AACnD,iBAAiB;AACjB;AACA;AACA,mCAAmC,8DAAQ;AAC3C,6BAA6B,wHAAwB;AACrD,2CAA2C,8DAAQ;AACnD,iBAAiB;AACjB;AACA;AACA,mCAAmC,8DAAQ;AAC3C;AACA;AACA;AACA;AACA,CAAC;AACD,8BAA8B,wHAAkB;AAChD;AACA;AACA,uBAAuB,8DAAQ;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,8DAAQ;AAC3C,6BAA6B,wHAAwB;AACrD,2CAA2C,8DAAQ;AACnD,iBAAiB;AACjB;AACA;AACA,mCAAmC,8DAAQ;AAC3C;AACA;AACA;AACA;AACA,CAAC;AACD,mCAAmC,wHAAkB;AACrD;AACA;AACA,uBAAuB,8DAAQ;AAC/B;AACA;AACA;AACA;AACA;AACA,mCAAmC,8DAAQ;AAC3C;AACA,iBAAiB;AACjB;AACA,mCAAmC,8DAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,kCAAkC,8DAAQ;AAC1C;AACA,qCAAqC,EAAE;AACvC;AACA;AACA;AACA;AACA,uCAAuC,wHAAwB;AAC/D,kCAAkC,8DAAQ;AAC1C;AACA,qCAAqC,EAAE;AACvC;AACA;AACA;AACA;AACA;AACA,8CAA8C,wHAAwB;AACtE,kCAAkC,8DAAQ;AAC1C;AACA,qCAAqC,EAAE;AACvC;AACA;AACA;AACA;AACA;AACA,kCAAkC,8DAAQ;AAC1C;AACA,qCAAqC,EAAE;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,8DAAQ;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,sCAAsC,8DAAQ;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,sCAAsC,8DAAQ;AAC9C;AACA;AACA;AACA;AACA,0CAA0C,8DAAQ;AAClD;AACA;AACA;AACA,0CAA0C,8DAAQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,8DAAQ;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,qDAAqD;AACnJ;AACA;AACA,8CAA8C,8DAAQ;AACtD;AACA,uGAAuG,EAAE;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,qDAAqD;AACnJ;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,4DAA4D,8EAAU;AACtE,OAAO,2EAAO,IAAI,+GAAqB;AACvC;AACA,+GAA8B;;AAEgB;;;;;;;;;;;;;;;;AC/O9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,uCAAuC,eAAe,4DAA4D,IAAI;AACtH;AACA,wCAAwC,eAAe,yBAAyB,IAAI;AACpF;AACA;AACA;AACA;AACA,mCAAmC,4DAA4D;AAC/F;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AAC8B;;;;;;;;;;;;;;;;;ACrGmE;AACjG,iCAAiC,wDAAwD,aAAa,iBAAiB,yBAAyB,WAAW,kEAAkE,iBAAiB,qCAAqC,4DAA4D,6DAA6D,wDAAwD,WAAW,yCAAyC,wBAAwB,SAAS,WAAW,kBAAkB,YAAY,cAAc,gBAAgB,oBAAoB,WAAW,oBAAoB,yCAAyC,sBAAsB,qBAAqB,gBAAgB,mBAAmB,iBAAiB,gBAAgB,eAAe,yCAAyC,kBAAkB,kBAAkB,gBAAgB,mBAAmB,mBAAmB,mBAAmB,UAAU,uBAAuB,kBAAkB,qBAAqB,mBAAmB,oBAAoB,yCAAyC;AACxmC,qGAAC,OAAO;AACuB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACH2D;AACpD;AACW;AACsD;AAC3C;AACS;AAC8D;AAChE;AACwB;AACJ;AACD;AACqB;AAClB;AACmC;AACf;AACxB;AACmB;AACM;AACiB;AAC/D;AACqC;AACO;AAC5G;AACA,UAAU,mDAAG;AACb,gFAAgF,iEAAU;AAC1F,aAAa;AACb,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,6DAAO;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,wEAAU;AAC/E,OAAO,qEAAO,IAAI,4HAA4B;AAC9C,OAAO,qEAAO,IAAI,yGAAwB;AAC1C,OAAO,qEAAO,IAAI,mFAAgB;AAClC,OAAO,qEAAO,IAAI,6GAAsB;AACxC,OAAO,qEAAO,IAAI,wGAAoB;AACtC,OAAO,qEAAO,IAAI,2GAAqB;AACvC,OAAO,qEAAO,IAAI,kGAAwB;AAC1C;AACA,kCAAkC,6EAAY;AAC9C;AACA;AACA;AACA,qBAAqB,iDAAQ;AAC7B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,iBAAiB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,iEAAU;AAClD,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,kFAAuB;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAS;AACjB,4DAA4D,iDAAQ;AACpE;AACA;AACA;AACA;AACA;AACA,8CAA8C,yDAAyD;AACvG;AACA,SAAS;AACT;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,4DAA4D,4HAAgC,IAAI,4EAA4E;AAC5K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2DAAK;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2DAAK,iGAAiG,kBAAkB,EAAE,0CAA0C;AAC5K,QAAQ,4DAAM,iDAAiD,uBAAuB;AACtF,QAAQ,4DAAM;AACd;AACA,YAAY,4DAAM;AAClB,0BAA0B,4DAAM;AAChC,0BAA0B,4DAAM;AAChC;AACA,gBAAgB,4DAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,mEAAa;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4DAAM;AAC1B;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAM;AAClB,0BAA0B,4DAAM;AAChC,0BAA0B,4DAAM;AAChC;AACA,gBAAgB,4DAAM,2HAA2H,aAAa,GAAG,mBAAmB;AACpL;AACA;AACA,oEAAoE,QAAQ;AAC5E;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAM;AAClB,iCAAiC,6FAAqB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4DAAM;AAC1B;AACA;AACA;AACA,gBAAgB,4DAAM;AACtB;AACA;AACA;AACA,YAAY,4DAAM;AAClB,0BAA0B,4DAAM;AAChC,0BAA0B,4DAAM;AAChC,YAAY,4DAAM,8HAA8H,yBAAyB;AACzK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAM;AAClB,wCAAwC,uFAA8B;AACtE;AACA;AACA,gBAAgB,4DAAM;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2HAA2H,cAAc;AACzI;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,wDAAK,6CAA6C,wDAAK;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mFAAa;AACxC,0BAA0B,mFAAa;AACvC,0BAA0B,mFAAa;AACvC,2BAA2B,mFAAa;AACxC,2BAA2B,mFAAa;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,QAAQ;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,QAAQ;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,+DAAK;AACtC;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,gFAAgF;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,+DAAK;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,qGAAiB;AAClC;AACA;AACA,gDAAgD,wBAAwB,IAAI,sDAAsD;AAClI;AACA;AACA;AACA,8CAA8C,wBAAwB,IAAI,sDAAsD;AAChI;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,wDAAwD;AAC9F;AACA;AACA;AACA;AACA;AACA,yDAAyD,wDAAK;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA0B;AAC1B,yFAAoB;AACqB;;;;;;;;;;;;;;;;;;AChiBK;AACqC;AACN;AAC7E,yBAAyB,wFAAkB;AAC3C;AACA,WAAW,kFAAiB;AAC5B;AACA,uBAAuB,iDAAQ;AAC/B;AACA,4BAA4B,SAAS,aAAa,KAAK,wBAAwB,KAAK,uBAAuB,KAAK,eAAe,GAAG;AAClI;AACA;AACA,gCAAgC,QAAQ,aAAa,KAAK,wBAAwB,KAAK,uBAAuB,KAAK,iBAAiB;AACpI;AACA;AACA,mCAAmC,iDAAQ;AAC3C;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB;AACA,mCAAmC,iDAAQ;AAC3C;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA,CAAC;AAC2B","sources":["webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/index.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/textmate.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/amdX.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/arrayOperation.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/textMateWorkerTokenizerController.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/threadedBackgroundTokenizerFactory.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/textMateTokenizationFeatureImpl.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/themes/common/tokenClassificationExtensionPoint.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/base/common/amd.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/workbench/contrib/codeEditor/browser/inspectEditorTokens/inspectEditorTokens.css.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/workbench/contrib/codeEditor/browser/inspectEditorTokens/inspectEditorTokens.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/workbench/services/textMate/common/TMGrammars.js"],"sourcesContent":["export { default } from './textmate.js';\nexport { ITextMateTokenizationService } from 'vscode/vscode/vs/workbench/services/textMate/browser/textMateTokenizationFeature.service';\n","import { StandaloneServices } from 'vscode/vscode/vs/editor/standalone/browser/standaloneServices';\nimport { ITextMateTokenizationService } from 'vscode/vscode/vs/workbench/services/textMate/browser/textMateTokenizationFeature.service';\nexport { ITextMateTokenizationService } from 'vscode/vscode/vs/workbench/services/textMate/browser/textMateTokenizationFeature.service';\nimport { SyncDescriptor } from 'vscode/vscode/vs/platform/instantiation/common/descriptors';\nimport { TextMateTokenizationFeature } from './vscode/src/vs/workbench/services/textMate/browser/textMateTokenizationFeatureImpl.js';\nimport { ILifecycleService } from 'vscode/vscode/vs/workbench/services/lifecycle/common/lifecycle.service';\nimport getServiceOverride$1 from '@codingame/monaco-vscode-files-service-override';\nimport { registerServiceInitializeParticipant } from 'vscode/lifecycle';\nimport { registerAssets } from 'vscode/assets';\nimport './vscode/src/vs/workbench/services/themes/common/tokenClassificationExtensionPoint.js';\nimport 'vscode/vscode/vs/workbench/contrib/codeEditor/browser/inspectEditorTokens/inspectEditorTokens';\n\nconst _onigWasm = new URL('vscode-oniguruma/release/onig.wasm', import.meta.url).href;\nregisterAssets({\n    'vscode-oniguruma/../onig.wasm': _onigWasm,\n    'vs/../../node_modules/vscode-oniguruma/release/onig.wasm': _onigWasm\n});\nregisterServiceInitializeParticipant(async (accessor) => {\n    void accessor\n        .get(ILifecycleService)\n        .when(2 )\n        .then(() => {\n        StandaloneServices.get(ITextMateTokenizationService);\n    });\n});\nfunction getServiceOverride() {\n    return {\n        ...getServiceOverride$1(),\n        [( ITextMateTokenizationService.toString())]: new SyncDescriptor(TextMateTokenizationFeature, [], false)\n    };\n}\n\nexport { getServiceOverride as default };\n","import { isESM } from 'vscode/vscode/vs/base/common/amd';\nimport { nodeModulesPath, FileAccess } from 'vscode/vscode/vs/base/common/network';\nimport 'vscode/vscode/vs/base/common/platform';\nimport { assertType } from 'vscode/vscode/vs/base/common/types';\nimport 'vscode/vscode/vs/base/common/path';\n\nfunction resolveAmdNodeModulePath(nodeModuleName, pathInsideNodeModule) {\n    assertType(isESM);\n    const product = globalThis._VSCODE_PRODUCT_JSON;\n    Boolean((product ?? globalThis.vscode?.context?.configuration()?.product)?.commit);\n    const nodeModulePath = `${nodeModuleName}/${pathInsideNodeModule}`;\n    const actualNodeModulesPath = (nodeModulesPath);\n    const resourcePath = `${actualNodeModulesPath}/${nodeModulePath}`;\n    return ( ( FileAccess.asBrowserUri(resourcePath)).toString(true));\n}\n\nexport { resolveAmdNodeModulePath };\n","import { compareBy, numberComparator } from 'vscode/vscode/vs/base/common/arrays';\n\nclass ArrayEdit {\n    constructor(\n    edits) {\n        this.edits = edits.slice().sort(compareBy(c => c.offset, numberComparator));\n    }\n    applyToArray(array) {\n        for (let i = this.edits.length - 1; i >= 0; i--) {\n            const c = this.edits[i];\n            array.splice(c.offset, c.length, ...( new Array(c.newLength)));\n        }\n    }\n}\nclass SingleArrayEdit {\n    constructor(offset, length, newLength) {\n        this.offset = offset;\n        this.length = length;\n        this.newLength = newLength;\n    }\n    toString() {\n        return `[${this.offset}, +${this.length}) -> +${this.newLength}}`;\n    }\n}\nclass MonotonousIndexTransformer {\n    static fromMany(transformations) {\n        const transformers = ( transformations.map(t => ( new MonotonousIndexTransformer(t))));\n        return ( new CombinedIndexTransformer(transformers));\n    }\n    constructor(transformation) {\n        this.transformation = transformation;\n        this.idx = 0;\n        this.offset = 0;\n    }\n    transform(index) {\n        let nextChange = this.transformation.edits[this.idx];\n        while (nextChange && nextChange.offset + nextChange.length <= index) {\n            this.offset += nextChange.newLength - nextChange.length;\n            this.idx++;\n            nextChange = this.transformation.edits[this.idx];\n        }\n        if (nextChange && nextChange.offset <= index) {\n            return undefined;\n        }\n        return index + this.offset;\n    }\n}\nclass CombinedIndexTransformer {\n    constructor(transformers) {\n        this.transformers = transformers;\n    }\n    transform(index) {\n        for (const transformer of this.transformers) {\n            const result = transformer.transform(index);\n            if (result === undefined) {\n                return undefined;\n            }\n            index = result;\n        }\n        return index;\n    }\n}\n\nexport { ArrayEdit, CombinedIndexTransformer, MonotonousIndexTransformer, SingleArrayEdit };\n","import { Disposable } from 'vscode/vscode/vs/base/common/lifecycle';\nimport 'vscode/vscode/vs/base/common/arrays';\nimport 'vscode/vscode/vs/base/common/event';\nimport { autorun } from 'vscode/vscode/vs/base/common/observableInternal/autorun';\nimport 'vscode/vscode/vs/base/common/observableInternal/derived';\nimport 'vscode/vscode/vs/base/common/cancellation';\nimport { keepObserved } from 'vscode/vscode/vs/base/common/observableInternal/utils';\nimport { countEOL } from 'vscode/vscode/vs/editor/common/core/eolCounter';\nimport { LineRange } from 'vscode/vscode/vs/editor/common/core/lineRange';\nimport { Range } from 'vscode/vscode/vs/editor/common/core/range';\nimport { TokenizationStateStore } from 'vscode/vscode/vs/editor/common/model/textModelTokens';\nimport { ContiguousMultilineTokensBuilder } from 'vscode/vscode/vs/editor/common/tokens/contiguousMultilineTokensBuilder';\nimport { observableConfigValue } from 'vscode/vscode/vs/platform/observable/common/platformObservableUtils';\nimport { MonotonousIndexTransformer, ArrayEdit, SingleArrayEdit } from '../arrayOperation.js';\n\nclass TextMateWorkerTokenizerController extends Disposable {\n    static { this._id = 0; }\n    constructor(_model, _worker, _languageIdCodec, _backgroundTokenizationStore, _configurationService, _maxTokenizationLineLength) {\n        super();\n        this._model = _model;\n        this._worker = _worker;\n        this._languageIdCodec = _languageIdCodec;\n        this._backgroundTokenizationStore = _backgroundTokenizationStore;\n        this._configurationService = _configurationService;\n        this._maxTokenizationLineLength = _maxTokenizationLineLength;\n        this.controllerId = TextMateWorkerTokenizerController._id++;\n        this._pendingChanges = [];\n        this._states = ( new TokenizationStateStore());\n        this._loggingEnabled = observableConfigValue('editor.experimental.asyncTokenizationLogging', false, this._configurationService);\n        this._register(keepObserved(this._loggingEnabled));\n        this._register(this._model.onDidChangeContent((e) => {\n            if (this._shouldLog) {\n                console.log('model change', {\n                    fileName: this._model.uri.fsPath.split('\\\\').pop(),\n                    changes: changesToString(e.changes),\n                });\n            }\n            this._worker.$acceptModelChanged(this.controllerId, e);\n            this._pendingChanges.push(e);\n        }));\n        this._register(this._model.onDidChangeLanguage((e) => {\n            const languageId = this._model.getLanguageId();\n            const encodedLanguageId = this._languageIdCodec.encodeLanguageId(languageId);\n            this._worker.$acceptModelLanguageChanged(this.controllerId, languageId, encodedLanguageId);\n        }));\n        const languageId = this._model.getLanguageId();\n        const encodedLanguageId = this._languageIdCodec.encodeLanguageId(languageId);\n        this._worker.$acceptNewModel({\n            uri: this._model.uri,\n            versionId: this._model.getVersionId(),\n            lines: this._model.getLinesContent(),\n            EOL: this._model.getEOL(),\n            languageId,\n            encodedLanguageId,\n            maxTokenizationLineLength: this._maxTokenizationLineLength.get(),\n            controllerId: this.controllerId,\n        });\n        this._register(autorun(reader => {\n            const maxTokenizationLineLength = this._maxTokenizationLineLength.read(reader);\n            this._worker.$acceptMaxTokenizationLineLength(this.controllerId, maxTokenizationLineLength);\n        }));\n    }\n    dispose() {\n        super.dispose();\n        this._worker.$acceptRemovedModel(this.controllerId);\n    }\n    requestTokens(startLineNumber, endLineNumberExclusive) {\n        this._worker.$retokenize(this.controllerId, startLineNumber, endLineNumberExclusive);\n    }\n    async setTokensAndStates(controllerId, versionId, rawTokens, stateDeltas) {\n        if (this.controllerId !== controllerId) {\n            return;\n        }\n        let tokens = ContiguousMultilineTokensBuilder.deserialize(( new Uint8Array(rawTokens)));\n        if (this._shouldLog) {\n            console.log('received background tokenization result', {\n                fileName: this._model.uri.fsPath.split('\\\\').pop(),\n                updatedTokenLines: ( tokens.map((t) => t.getLineRange())).join(' & '),\n                updatedStateLines: ( stateDeltas.map((s) => ( ( new LineRange(s.startLineNumber, s.startLineNumber + s.stateDeltas.length)).toString()))).join(' & '),\n            });\n        }\n        if (this._shouldLog) {\n            const changes = ( ( this._pendingChanges.filter(c => c.versionId <= versionId).map(c => c.changes)).map(c => changesToString(c))).join(' then ');\n            console.log('Applying changes to local states', changes);\n        }\n        while (this._pendingChanges.length > 0 &&\n            this._pendingChanges[0].versionId <= versionId) {\n            const change = this._pendingChanges.shift();\n            this._states.acceptChanges(change.changes);\n        }\n        if (this._pendingChanges.length > 0) {\n            if (this._shouldLog) {\n                const changes = ( ( this._pendingChanges.map(c => c.changes)).map(c => changesToString(c))).join(' then ');\n                console.log('Considering non-processed changes', changes);\n            }\n            const curToFutureTransformerTokens = MonotonousIndexTransformer.fromMany(( this._pendingChanges.map((c) => fullLineArrayEditFromModelContentChange(c.changes))));\n            const b = ( new ContiguousMultilineTokensBuilder());\n            for (const t of tokens) {\n                for (let i = t.startLineNumber; i <= t.endLineNumber; i++) {\n                    const result = curToFutureTransformerTokens.transform(i - 1);\n                    if (result !== undefined) {\n                        b.add(i, t.getLineTokens(i));\n                    }\n                }\n            }\n            tokens = b.finalize();\n            for (const change of this._pendingChanges) {\n                for (const innerChanges of change.changes) {\n                    for (let j = 0; j < tokens.length; j++) {\n                        tokens[j].applyEdit(innerChanges.range, innerChanges.text);\n                    }\n                }\n            }\n        }\n        const curToFutureTransformerStates = MonotonousIndexTransformer.fromMany(( this._pendingChanges.map((c) => fullLineArrayEditFromModelContentChange(c.changes))));\n        if (!this._applyStateStackDiffFn || !this._initialState) {\n            const { applyStateStackDiff, INITIAL } = await import('vscode-textmate').then(module => module.default ?? module);\n            this._applyStateStackDiffFn = applyStateStackDiff;\n            this._initialState = INITIAL;\n        }\n        for (const d of stateDeltas) {\n            let prevState = d.startLineNumber <= 1 ? this._initialState : this._states.getEndState(d.startLineNumber - 1);\n            for (let i = 0; i < d.stateDeltas.length; i++) {\n                const delta = d.stateDeltas[i];\n                let state;\n                if (delta) {\n                    state = this._applyStateStackDiffFn(prevState, delta);\n                    this._states.setEndState(d.startLineNumber + i, state);\n                }\n                else {\n                    state = this._states.getEndState(d.startLineNumber + i);\n                }\n                const offset = curToFutureTransformerStates.transform(d.startLineNumber + i - 1);\n                if (offset !== undefined) {\n                    this._backgroundTokenizationStore.setEndState(offset + 1, state);\n                }\n                if (d.startLineNumber + i >= this._model.getLineCount() - 1) {\n                    this._backgroundTokenizationStore.backgroundTokenizationFinished();\n                }\n                prevState = state;\n            }\n        }\n        this._backgroundTokenizationStore.setTokens(tokens);\n    }\n    get _shouldLog() { return this._loggingEnabled.get(); }\n}\nfunction fullLineArrayEditFromModelContentChange(c) {\n    return ( new ArrayEdit(( c.map((c) => ( new SingleArrayEdit(\n        c.range.startLineNumber - 1,\n        c.range.endLineNumber - c.range.startLineNumber + 1,\n        countEOL(c.text)[0] + 1\n    ))))));\n}\nfunction changesToString(changes) {\n    return ( changes.map(c => ( Range.lift(c.range).toString()) + ' => ' + c.text)).join(' & ');\n}\n\nexport { TextMateWorkerTokenizerController };\n","import { __decorate, __param } from 'vscode/external/tslib/tslib.es6.js';\nimport { DisposableStore, toDisposable } from 'vscode/vscode/vs/base/common/lifecycle';\nimport { nodeModulesPath, FileAccess } from 'vscode/vscode/vs/base/common/network';\nimport 'vscode/vscode/vs/base/common/platform';\nimport { URI } from 'vscode/vscode/vs/base/common/uri';\nimport { ILanguageService } from 'vscode/vscode/vs/editor/common/languages/language';\nimport { IConfigurationService } from 'vscode/vscode/vs/platform/configuration/common/configuration.service';\nimport { IEnvironmentService } from 'vscode/vscode/vs/platform/environment/common/environment.service';\nimport { IExtensionResourceLoaderService } from 'vscode/vscode/vs/platform/extensionResourceLoader/common/extensionResourceLoader.service';\nimport { INotificationService } from 'vscode/vscode/vs/platform/notification/common/notification.service';\nimport { ITelemetryService } from 'vscode/vscode/vs/platform/telemetry/common/telemetry.service';\nimport { TextMateWorkerHost } from './worker/textMateWorkerHost.js';\nimport { TextMateWorkerTokenizerController } from './textMateWorkerTokenizerController.js';\nimport { createWebWorker } from 'vscode/vscode/vs/base/browser/defaultWorkerFactory';\n\nvar ThreadedBackgroundTokenizerFactory_1;\nlet ThreadedBackgroundTokenizerFactory = class ThreadedBackgroundTokenizerFactory {\n    static { ThreadedBackgroundTokenizerFactory_1 = this; }\n    static { this._reportedMismatchingTokens = false; }\n    constructor(_reportTokenizationTime, _shouldTokenizeAsync, _extensionResourceLoaderService, _configurationService, _languageService, _environmentService, _notificationService, _telemetryService) {\n        this._reportTokenizationTime = _reportTokenizationTime;\n        this._shouldTokenizeAsync = _shouldTokenizeAsync;\n        this._extensionResourceLoaderService = _extensionResourceLoaderService;\n        this._configurationService = _configurationService;\n        this._languageService = _languageService;\n        this._environmentService = _environmentService;\n        this._notificationService = _notificationService;\n        this._telemetryService = _telemetryService;\n        this._workerProxyPromise = null;\n        this._worker = null;\n        this._workerProxy = null;\n        this._workerTokenizerControllers = ( new Map());\n        this._currentTheme = null;\n        this._currentTokenColorMap = null;\n        this._grammarDefinitions = [];\n    }\n    dispose() {\n        this._disposeWorker();\n    }\n    createBackgroundTokenizer(textModel, tokenStore, maxTokenizationLineLength) {\n        if (!this._shouldTokenizeAsync() || textModel.isTooLargeForSyncing()) {\n            return undefined;\n        }\n        const store = ( new DisposableStore());\n        const controllerContainer = this._getWorkerProxy().then((workerProxy) => {\n            if (store.isDisposed || !workerProxy) {\n                return undefined;\n            }\n            const controllerContainer = { controller: undefined, worker: this._worker };\n            store.add(keepAliveWhenAttached(textModel, () => {\n                const controller = ( new TextMateWorkerTokenizerController(\n                    textModel,\n                    workerProxy,\n                    this._languageService.languageIdCodec,\n                    tokenStore,\n                    this._configurationService,\n                    maxTokenizationLineLength\n                ));\n                controllerContainer.controller = controller;\n                this._workerTokenizerControllers.set(controller.controllerId, controller);\n                return toDisposable(() => {\n                    controllerContainer.controller = undefined;\n                    this._workerTokenizerControllers.delete(controller.controllerId);\n                    controller.dispose();\n                });\n            }));\n            return controllerContainer;\n        });\n        return {\n            dispose() {\n                store.dispose();\n            },\n            requestTokens: async (startLineNumber, endLineNumberExclusive) => {\n                const container = await controllerContainer;\n                if (container?.controller && container.worker === this._worker) {\n                    container.controller.requestTokens(startLineNumber, endLineNumberExclusive);\n                }\n            },\n            reportMismatchingTokens: (lineNumber) => {\n                if (ThreadedBackgroundTokenizerFactory_1._reportedMismatchingTokens) {\n                    return;\n                }\n                ThreadedBackgroundTokenizerFactory_1._reportedMismatchingTokens = true;\n                this._notificationService.error({\n                    message: 'Async Tokenization Token Mismatch in line ' + lineNumber,\n                    name: 'Async Tokenization Token Mismatch',\n                });\n                this._telemetryService.publicLog2('asyncTokenizationMismatchingTokens', {});\n            },\n        };\n    }\n    setGrammarDefinitions(grammarDefinitions) {\n        this._grammarDefinitions = grammarDefinitions;\n        this._disposeWorker();\n    }\n    acceptTheme(theme, colorMap) {\n        this._currentTheme = theme;\n        this._currentTokenColorMap = colorMap;\n        if (this._currentTheme && this._currentTokenColorMap && this._workerProxy) {\n            this._workerProxy.$acceptTheme(this._currentTheme, this._currentTokenColorMap);\n        }\n    }\n    _getWorkerProxy() {\n        if (!this._workerProxyPromise) {\n            this._workerProxyPromise = this._createWorkerProxy();\n        }\n        return this._workerProxyPromise;\n    }\n    async _createWorkerProxy() {\n        const onigurumaModuleLocation = `${nodeModulesPath}/vscode-oniguruma`;\n        const onigurumaLocation = onigurumaModuleLocation;\n        const onigurumaWASM = `${onigurumaLocation}/release/onig.wasm`;\n        const createData = {\n            grammarDefinitions: this._grammarDefinitions,\n            onigurumaWASMUri: ( ( FileAccess.asBrowserUri(onigurumaWASM)).toString(true)),\n        };\n        const worker = this._worker = createWebWorker('vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.worker', 'TextMateWorker');\n        TextMateWorkerHost.setChannel(worker, {\n            $readFile: async (_resource) => {\n                const resource = URI.revive(_resource);\n                return this._extensionResourceLoaderService.readExtensionResource(resource);\n            },\n            $setTokensAndStates: async (controllerId, versionId, tokens, lineEndStateDeltas) => {\n                const controller = this._workerTokenizerControllers.get(controllerId);\n                if (controller) {\n                    controller.setTokensAndStates(controllerId, versionId, tokens, lineEndStateDeltas);\n                }\n            },\n            $reportTokenizationTime: (timeMs, languageId, sourceExtensionId, lineLength, isRandomSample) => {\n                this._reportTokenizationTime(timeMs, languageId, sourceExtensionId, lineLength, isRandomSample);\n            }\n        });\n        await worker.proxy.$init(createData);\n        if (this._worker !== worker) {\n            return null;\n        }\n        this._workerProxy = worker.proxy;\n        if (this._currentTheme && this._currentTokenColorMap) {\n            this._workerProxy.$acceptTheme(this._currentTheme, this._currentTokenColorMap);\n        }\n        return worker.proxy;\n    }\n    _disposeWorker() {\n        for (const controller of ( this._workerTokenizerControllers.values())) {\n            controller.dispose();\n        }\n        this._workerTokenizerControllers.clear();\n        if (this._worker) {\n            this._worker.dispose();\n            this._worker = null;\n        }\n        this._workerProxy = null;\n        this._workerProxyPromise = null;\n    }\n};\nThreadedBackgroundTokenizerFactory = ThreadedBackgroundTokenizerFactory_1 = ( __decorate([\n    ( __param(2, IExtensionResourceLoaderService)),\n    ( __param(3, IConfigurationService)),\n    ( __param(4, ILanguageService)),\n    ( __param(5, IEnvironmentService)),\n    ( __param(6, INotificationService)),\n    ( __param(7, ITelemetryService))\n], ThreadedBackgroundTokenizerFactory));\nfunction keepAliveWhenAttached(textModel, factory) {\n    const disposableStore = ( new DisposableStore());\n    const subStore = disposableStore.add(( new DisposableStore()));\n    function checkAttached() {\n        if (textModel.isAttachedToEditor()) {\n            subStore.add(factory());\n        }\n        else {\n            subStore.clear();\n        }\n    }\n    checkAttached();\n    disposableStore.add(textModel.onDidChangeAttached(() => {\n        checkAttached();\n    }));\n    return disposableStore;\n}\n\nexport { ThreadedBackgroundTokenizerFactory };\n","import { __decorate, __param } from 'vscode/external/tslib/tslib.es6.js';\nimport { resolveAmdNodeModulePath } from '../../../../amdX.js';\nimport { createStyleSheet } from 'vscode/vscode/vs/base/browser/dom';\nimport { equals } from 'vscode/vscode/vs/base/common/arrays';\nimport { Color } from 'vscode/vscode/vs/base/common/color';\nimport { onUnexpectedError } from 'vscode/vscode/vs/base/common/errors';\nimport { Disposable, DisposableStore } from 'vscode/vscode/vs/base/common/lifecycle';\nimport { FileAccess, nodeModulesPath } from 'vscode/vscode/vs/base/common/network';\nimport 'vscode/vscode/vs/base/common/event';\nimport 'vscode/vscode/vs/base/common/observableInternal/autorun';\nimport 'vscode/vscode/vs/base/common/observableInternal/derived';\nimport 'vscode/vscode/vs/base/common/cancellation';\nimport { observableFromEvent } from 'vscode/vscode/vs/base/common/observableInternal/utils';\nimport { isWeb } from 'vscode/vscode/vs/base/common/platform';\nimport { joinPath, isEqualOrParent } from 'vscode/vscode/vs/base/common/resources';\nimport { isObject } from 'vscode/vscode/vs/base/common/types';\nimport { LazyTokenizationSupport, TokenizationRegistry } from 'vscode/vscode/vs/editor/common/languages';\nimport { ILanguageService } from 'vscode/vscode/vs/editor/common/languages/language';\nimport { generateTokensCSSForColorMap } from 'vscode/vscode/vs/editor/common/languages/supports/tokenization';\nimport { localize } from 'vscode/vscode/vs/nls';\nimport { IConfigurationService } from 'vscode/vscode/vs/platform/configuration/common/configuration.service';\nimport { IExtensionResourceLoaderService } from 'vscode/vscode/vs/platform/extensionResourceLoader/common/extensionResourceLoader.service';\nimport { IInstantiationService } from 'vscode/vscode/vs/platform/instantiation/common/instantiation';\nimport { ILogService } from 'vscode/vscode/vs/platform/log/common/log.service';\nimport { INotificationService } from 'vscode/vscode/vs/platform/notification/common/notification.service';\nimport { IProgressService } from 'vscode/vscode/vs/platform/progress/common/progress.service';\nimport { ITelemetryService } from 'vscode/vscode/vs/platform/telemetry/common/telemetry.service';\nimport { IWorkbenchEnvironmentService } from 'vscode/vscode/vs/workbench/services/environment/common/environmentService.service';\nimport { TextMateTokenizationSupport } from './tokenizationSupport/textMateTokenizationSupport.js';\nimport { TokenizationSupportWithLineLimit } from './tokenizationSupport/tokenizationSupportWithLineLimit.js';\nimport { ThreadedBackgroundTokenizerFactory } from './backgroundTokenization/threadedBackgroundTokenizerFactory.js';\nimport { TMGrammarFactory, missingTMGrammarErrorMessage } from '../common/TMGrammarFactory.js';\nimport { grammarsExtPoint } from 'vscode/vscode/vs/workbench/services/textMate/common/TMGrammars';\nimport { IWorkbenchThemeService } from 'vscode/vscode/vs/workbench/services/themes/common/workbenchThemeService.service';\n\nvar TextMateTokenizationFeature_1;\nlet TextMateTokenizationFeature = class TextMateTokenizationFeature extends Disposable {\n    static { TextMateTokenizationFeature_1 = this; }\n    static { this.reportTokenizationTimeCounter = { sync: 0, async: 0 }; }\n    constructor(_languageService, _themeService, _extensionResourceLoaderService, _notificationService, _logService, _configurationService, _progressService, _environmentService, _instantiationService, _telemetryService) {\n        super();\n        this._languageService = _languageService;\n        this._themeService = _themeService;\n        this._extensionResourceLoaderService = _extensionResourceLoaderService;\n        this._notificationService = _notificationService;\n        this._logService = _logService;\n        this._configurationService = _configurationService;\n        this._progressService = _progressService;\n        this._environmentService = _environmentService;\n        this._instantiationService = _instantiationService;\n        this._telemetryService = _telemetryService;\n        this._createdModes = [];\n        this._encounteredLanguages = [];\n        this._debugMode = false;\n        this._debugModePrintFunc = () => { };\n        this._grammarDefinitions = null;\n        this._grammarFactory = null;\n        this._tokenizersRegistrations = ( (new DisposableStore()));\n        this._currentTheme = null;\n        this._currentTokenColorMap = null;\n        this._threadedBackgroundTokenizerFactory = this._instantiationService.createInstance(ThreadedBackgroundTokenizerFactory, (timeMs, languageId, sourceExtensionId, lineLength, isRandomSample) => this._reportTokenizationTime(timeMs, languageId, sourceExtensionId, lineLength, true, isRandomSample), () => this.getAsyncTokenizationEnabled());\n        this._vscodeOniguruma = null;\n        this._styleElement = createStyleSheet();\n        this._styleElement.className = 'vscode-tokens-styles';\n        grammarsExtPoint.setHandler((extensions) => this._handleGrammarsExtPoint(extensions));\n        this._updateTheme(this._themeService.getColorTheme(), true);\n        this._register(this._themeService.onDidColorThemeChange(() => {\n            this._updateTheme(this._themeService.getColorTheme(), false);\n        }));\n        this._register(this._languageService.onDidRequestRichLanguageFeatures((languageId) => {\n            this._createdModes.push(languageId);\n        }));\n    }\n    getAsyncTokenizationEnabled() {\n        return !!this._configurationService.getValue('editor.experimental.asyncTokenization');\n    }\n    getAsyncTokenizationVerification() {\n        return !!this._configurationService.getValue('editor.experimental.asyncTokenizationVerification');\n    }\n    _handleGrammarsExtPoint(extensions) {\n        this._grammarDefinitions = null;\n        if (this._grammarFactory) {\n            this._grammarFactory.dispose();\n            this._grammarFactory = null;\n        }\n        this._tokenizersRegistrations.clear();\n        this._grammarDefinitions = [];\n        for (const extension of extensions) {\n            const grammars = extension.value;\n            for (const grammar of grammars) {\n                const validatedGrammar = this._validateGrammarDefinition(extension, grammar);\n                if (validatedGrammar) {\n                    this._grammarDefinitions.push(validatedGrammar);\n                    if (validatedGrammar.language) {\n                        const lazyTokenizationSupport = ( (new LazyTokenizationSupport(() => this._createTokenizationSupport(validatedGrammar.language))));\n                        this._tokenizersRegistrations.add(lazyTokenizationSupport);\n                        this._tokenizersRegistrations.add(TokenizationRegistry.registerFactory(validatedGrammar.language, lazyTokenizationSupport));\n                    }\n                }\n            }\n        }\n        this._threadedBackgroundTokenizerFactory.setGrammarDefinitions(this._grammarDefinitions);\n        for (const createdMode of this._createdModes) {\n            TokenizationRegistry.getOrCreate(createdMode);\n        }\n    }\n    _validateGrammarDefinition(extension, grammar) {\n        if (!validateGrammarExtensionPoint(extension.description.extensionLocation, grammar, extension.collector, this._languageService)) {\n            return null;\n        }\n        const grammarLocation = joinPath(extension.description.extensionLocation, grammar.path);\n        const embeddedLanguages = Object.create(null);\n        if (grammar.embeddedLanguages) {\n            const scopes = ( (Object.keys(grammar.embeddedLanguages)));\n            for (let i = 0, len = scopes.length; i < len; i++) {\n                const scope = scopes[i];\n                const language = grammar.embeddedLanguages[scope];\n                if (typeof language !== 'string') {\n                    continue;\n                }\n                if (this._languageService.isRegisteredLanguageId(language)) {\n                    embeddedLanguages[scope] = this._languageService.languageIdCodec.encodeLanguageId(language);\n                }\n            }\n        }\n        const tokenTypes = Object.create(null);\n        if (grammar.tokenTypes) {\n            const scopes = ( (Object.keys(grammar.tokenTypes)));\n            for (const scope of scopes) {\n                const tokenType = grammar.tokenTypes[scope];\n                switch (tokenType) {\n                    case 'string':\n                        tokenTypes[scope] = 2 ;\n                        break;\n                    case 'other':\n                        tokenTypes[scope] = 0 ;\n                        break;\n                    case 'comment':\n                        tokenTypes[scope] = 1 ;\n                        break;\n                }\n            }\n        }\n        const validLanguageId = grammar.language && this._languageService.isRegisteredLanguageId(grammar.language) ? grammar.language : undefined;\n        function asStringArray(array, defaultValue) {\n            if (!Array.isArray(array)) {\n                return defaultValue;\n            }\n            if (!array.every(e => typeof e === 'string')) {\n                return defaultValue;\n            }\n            return array;\n        }\n        return {\n            location: grammarLocation,\n            language: validLanguageId,\n            scopeName: grammar.scopeName,\n            embeddedLanguages: embeddedLanguages,\n            tokenTypes: tokenTypes,\n            injectTo: grammar.injectTo,\n            balancedBracketSelectors: asStringArray(grammar.balancedBracketScopes, ['*']),\n            unbalancedBracketSelectors: asStringArray(grammar.unbalancedBracketScopes, []),\n            sourceExtensionId: extension.description.id,\n        };\n    }\n    startDebugMode(printFn, onStop) {\n        if (this._debugMode) {\n            this._notificationService.error(( localize(3082, \"Already Logging.\")));\n            return;\n        }\n        this._debugModePrintFunc = printFn;\n        this._debugMode = true;\n        if (this._debugMode) {\n            this._progressService.withProgress({\n                location: 15 ,\n                buttons: [( localize(3083, \"Stop\"))]\n            }, (progress) => {\n                progress.report({\n                    message: ( localize(3084, \"Preparing to log TM Grammar parsing. Press Stop when finished.\"))\n                });\n                return this._getVSCodeOniguruma().then((vscodeOniguruma) => {\n                    vscodeOniguruma.setDefaultDebugCall(true);\n                    progress.report({\n                        message: ( localize(3085, \"Now logging TM Grammar parsing. Press Stop when finished.\"))\n                    });\n                    return (\n                         (new Promise((resolve, reject) => { }))\n                    );\n                });\n            }, (choice) => {\n                this._getVSCodeOniguruma().then((vscodeOniguruma) => {\n                    this._debugModePrintFunc = () => { };\n                    this._debugMode = false;\n                    vscodeOniguruma.setDefaultDebugCall(false);\n                    onStop();\n                });\n            });\n        }\n    }\n    _canCreateGrammarFactory() {\n        return !!this._grammarDefinitions;\n    }\n    async _getOrCreateGrammarFactory() {\n        if (this._grammarFactory) {\n            return this._grammarFactory;\n        }\n        const [vscodeTextmate, vscodeOniguruma] = await Promise.all([import('vscode-textmate').then(module => module.default ?? module), this._getVSCodeOniguruma()]);\n        const onigLib = Promise.resolve({\n            createOnigScanner: (sources) => vscodeOniguruma.createOnigScanner(sources),\n            createOnigString: (str) => vscodeOniguruma.createOnigString(str)\n        });\n        if (this._grammarFactory) {\n            return this._grammarFactory;\n        }\n        this._grammarFactory = ( (new TMGrammarFactory({\n            logTrace: (msg) => this._logService.trace(msg),\n            logError: (msg, err) => this._logService.error(msg, err),\n            readFile: (resource) => this._extensionResourceLoaderService.readExtensionResource(resource)\n        }, this._grammarDefinitions || [], vscodeTextmate, onigLib)));\n        this._updateTheme(this._themeService.getColorTheme(), true);\n        return this._grammarFactory;\n    }\n    async _createTokenizationSupport(languageId) {\n        if (!this._languageService.isRegisteredLanguageId(languageId)) {\n            return null;\n        }\n        if (!this._canCreateGrammarFactory()) {\n            return null;\n        }\n        try {\n            const grammarFactory = await this._getOrCreateGrammarFactory();\n            if (!( (grammarFactory.has(languageId)))) {\n                return null;\n            }\n            const encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n            const r = await grammarFactory.createGrammar(languageId, encodedLanguageId);\n            if (!r.grammar) {\n                return null;\n            }\n            const maxTokenizationLineLength = observableConfigValue('editor.maxTokenizationLineLength', languageId, -1, this._configurationService);\n            const tokenization = ( (new TextMateTokenizationSupport(\n                r.grammar,\n                r.initialState,\n                r.containsEmbeddedLanguages,\n                (textModel, tokenStore) => this._threadedBackgroundTokenizerFactory.createBackgroundTokenizer(textModel, tokenStore, maxTokenizationLineLength),\n                () => this.getAsyncTokenizationVerification(),\n                (timeMs, lineLength, isRandomSample) => {\n                    this._reportTokenizationTime(timeMs, languageId, r.sourceExtensionId, lineLength, false, isRandomSample);\n                },\n                true\n            )));\n            const disposable = tokenization.onDidEncounterLanguage((encodedLanguageId) => {\n                if (!this._encounteredLanguages[encodedLanguageId]) {\n                    const languageId = this._languageService.languageIdCodec.decodeLanguageId(encodedLanguageId);\n                    this._encounteredLanguages[encodedLanguageId] = true;\n                    this._languageService.requestBasicLanguageFeatures(languageId);\n                }\n            });\n            return (\n                 (new TokenizationSupportWithLineLimit(encodedLanguageId, tokenization, disposable, maxTokenizationLineLength))\n            );\n        }\n        catch (err) {\n            if (err.message && err.message === missingTMGrammarErrorMessage) {\n                return null;\n            }\n            onUnexpectedError(err);\n            return null;\n        }\n    }\n    _updateTheme(colorTheme, forceUpdate) {\n        if (!forceUpdate && this._currentTheme && this._currentTokenColorMap && equalsTokenRules(this._currentTheme.settings, colorTheme.tokenColors)\n            && equals(this._currentTokenColorMap, colorTheme.tokenColorMap)) {\n            return;\n        }\n        this._currentTheme = { name: colorTheme.label, settings: colorTheme.tokenColors };\n        this._currentTokenColorMap = colorTheme.tokenColorMap;\n        this._grammarFactory?.setTheme(this._currentTheme, this._currentTokenColorMap);\n        const colorMap = toColorMap(this._currentTokenColorMap);\n        const cssRules = generateTokensCSSForColorMap(colorMap);\n        this._styleElement.textContent = cssRules;\n        TokenizationRegistry.setColorMap(colorMap);\n        if (this._currentTheme && this._currentTokenColorMap) {\n            this._threadedBackgroundTokenizerFactory.acceptTheme(this._currentTheme, this._currentTokenColorMap);\n        }\n    }\n    async createTokenizer(languageId) {\n        if (!this._languageService.isRegisteredLanguageId(languageId)) {\n            return null;\n        }\n        const grammarFactory = await this._getOrCreateGrammarFactory();\n        if (!( (grammarFactory.has(languageId)))) {\n            return null;\n        }\n        const encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n        const { grammar } = await grammarFactory.createGrammar(languageId, encodedLanguageId);\n        return grammar;\n    }\n    _getVSCodeOniguruma() {\n        if (!this._vscodeOniguruma) {\n            this._vscodeOniguruma = (async () => {\n                const [vscodeOniguruma, wasm] = await Promise.all([import('vscode-oniguruma').then(module => module.default ?? module), this._loadVSCodeOnigurumaWASM()]);\n                await vscodeOniguruma.loadWASM({\n                    data: wasm,\n                    print: (str) => {\n                        this._debugModePrintFunc(str);\n                    }\n                });\n                return vscodeOniguruma;\n            })();\n        }\n        return this._vscodeOniguruma;\n    }\n    async _loadVSCodeOnigurumaWASM() {\n        if (isWeb) {\n            const response = await fetch(resolveAmdNodeModulePath('vscode-oniguruma', 'release/onig.wasm')\n                );\n            return await response.arrayBuffer();\n        }\n        else {\n            const response = await fetch(( (( (FileAccess.asBrowserUri(`${nodeModulesPath}/vscode-oniguruma/release/onig.wasm`))).toString(true))));\n            return response;\n        }\n    }\n    _reportTokenizationTime(timeMs, languageId, sourceExtensionId, lineLength, fromWorker, isRandomSample) {\n        const key = fromWorker ? 'async' : 'sync';\n        if (TextMateTokenizationFeature_1.reportTokenizationTimeCounter[key] > 50) {\n            return;\n        }\n        if (TextMateTokenizationFeature_1.reportTokenizationTimeCounter[key] === 0) {\n            setTimeout(() => {\n                TextMateTokenizationFeature_1.reportTokenizationTimeCounter[key] = 0;\n            }, 1000 * 60 * 60);\n        }\n        TextMateTokenizationFeature_1.reportTokenizationTimeCounter[key]++;\n        this._telemetryService.publicLog2('editor.tokenizedLine', {\n            timeMs,\n            languageId,\n            lineLength,\n            fromWorker,\n            sourceExtensionId,\n            isRandomSample,\n            tokenizationSetting: this.getAsyncTokenizationEnabled() ? (this.getAsyncTokenizationVerification() ? 2 : 1) : 0,\n        });\n    }\n};\nTextMateTokenizationFeature = TextMateTokenizationFeature_1 = ( (__decorate([\n    ( (__param(0, ILanguageService))),\n    ( (__param(1, IWorkbenchThemeService))),\n    ( (__param(2, IExtensionResourceLoaderService))),\n    ( (__param(3, INotificationService))),\n    ( (__param(4, ILogService))),\n    ( (__param(5, IConfigurationService))),\n    ( (__param(6, IProgressService))),\n    ( (__param(7, IWorkbenchEnvironmentService))),\n    ( (__param(8, IInstantiationService))),\n    ( (__param(9, ITelemetryService)))\n], TextMateTokenizationFeature)));\nfunction toColorMap(colorMap) {\n    const result = [null];\n    for (let i = 1, len = colorMap.length; i < len; i++) {\n        result[i] = ( (Color.fromHex(colorMap[i])));\n    }\n    return result;\n}\nfunction equalsTokenRules(a, b) {\n    if (!b || !a || b.length !== a.length) {\n        return false;\n    }\n    for (let i = b.length - 1; i >= 0; i--) {\n        const r1 = b[i];\n        const r2 = a[i];\n        if (r1.scope !== r2.scope) {\n            return false;\n        }\n        const s1 = r1.settings;\n        const s2 = r2.settings;\n        if (s1 && s2) {\n            if (s1.fontStyle !== s2.fontStyle || s1.foreground !== s2.foreground || s1.background !== s2.background) {\n                return false;\n            }\n        }\n        else if (!s1 || !s2) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction validateGrammarExtensionPoint(extensionLocation, syntax, collector, _languageService) {\n    if (syntax.language && ((typeof syntax.language !== 'string') || !_languageService.isRegisteredLanguageId(syntax.language))) {\n        collector.error(( localize(\n            3086,\n            \"Unknown language in `contributes.{0}.language`. Provided value: {1}\",\n            grammarsExtPoint.name,\n            String(syntax.language)\n        )));\n        return false;\n    }\n    if (!syntax.scopeName || (typeof syntax.scopeName !== 'string')) {\n        collector.error(( localize(\n            3087,\n            \"Expected string in `contributes.{0}.scopeName`. Provided value: {1}\",\n            grammarsExtPoint.name,\n            String(syntax.scopeName)\n        )));\n        return false;\n    }\n    if (!syntax.path || (typeof syntax.path !== 'string')) {\n        collector.error(( localize(\n            3088,\n            \"Expected string in `contributes.{0}.path`. Provided value: {1}\",\n            grammarsExtPoint.name,\n            String(syntax.path)\n        )));\n        return false;\n    }\n    if (syntax.injectTo && (!Array.isArray(syntax.injectTo) || ( (syntax.injectTo.some(scope => typeof scope !== 'string'))))) {\n        collector.error(( localize(\n            3089,\n            \"Invalid value in `contributes.{0}.injectTo`. Must be an array of language scope names. Provided value: {1}\",\n            grammarsExtPoint.name,\n            JSON.stringify(syntax.injectTo)\n        )));\n        return false;\n    }\n    if (syntax.embeddedLanguages && !isObject(syntax.embeddedLanguages)) {\n        collector.error(( localize(\n            3090,\n            \"Invalid value in `contributes.{0}.embeddedLanguages`. Must be an object map from scope name to language. Provided value: {1}\",\n            grammarsExtPoint.name,\n            JSON.stringify(syntax.embeddedLanguages)\n        )));\n        return false;\n    }\n    if (syntax.tokenTypes && !isObject(syntax.tokenTypes)) {\n        collector.error(( localize(\n            3091,\n            \"Invalid value in `contributes.{0}.tokenTypes`. Must be an object map from scope name to token type. Provided value: {1}\",\n            grammarsExtPoint.name,\n            JSON.stringify(syntax.tokenTypes)\n        )));\n        return false;\n    }\n    const grammarLocation = joinPath(extensionLocation, syntax.path);\n    if (!isEqualOrParent(grammarLocation, extensionLocation)) {\n        collector.warn(( localize(\n            3092,\n            \"Expected `contributes.{0}.path` ({1}) to be included inside extension's folder ({2}). This might make the extension non-portable.\",\n            grammarsExtPoint.name,\n            grammarLocation.path,\n            extensionLocation.path\n        )));\n    }\n    return true;\n}\nfunction observableConfigValue(key, languageId, defaultValue, configurationService) {\n    return observableFromEvent((handleChange) => configurationService.onDidChangeConfiguration(e => {\n        if (e.affectsConfiguration(key, { overrideIdentifier: languageId })) {\n            handleChange(e);\n        }\n    }), () => configurationService.getValue(key, { overrideIdentifier: languageId }) ?? defaultValue);\n}\n\nexport { TextMateTokenizationFeature };\n","import { __decorate, __param } from 'vscode/external/tslib/tslib.es6.js';\nimport { localize } from 'vscode/vscode/vs/nls';\nimport { ExtensionsRegistry } from 'vscode/vscode/vs/workbench/services/extensions/common/extensionsRegistry';\nimport { getTokenClassificationRegistry, typeAndModifierIdPattern } from 'vscode/vscode/vs/platform/theme/common/tokenClassificationRegistry';\nimport { registerWorkbenchContribution2 } from 'vscode/vscode/vs/workbench/common/contributions';\nimport { IInstantiationService } from 'vscode/vscode/vs/platform/instantiation/common/instantiation';\n\nconst tokenClassificationRegistry = getTokenClassificationRegistry();\nconst tokenTypeExtPoint = ExtensionsRegistry.registerExtensionPoint({\n    extensionPoint: 'semanticTokenTypes',\n    jsonSchema: {\n        description: ( localize(3093, 'Contributes semantic token types.')),\n        type: 'array',\n        items: {\n            type: 'object',\n            properties: {\n                id: {\n                    type: 'string',\n                    description: ( localize(3094, 'The identifier of the semantic token type')),\n                    pattern: typeAndModifierIdPattern,\n                    patternErrorMessage: ( localize(3095, 'Identifiers should be in the form letterOrDigit[_-letterOrDigit]*')),\n                },\n                superType: {\n                    type: 'string',\n                    description: ( localize(3096, 'The super type of the semantic token type')),\n                    pattern: typeAndModifierIdPattern,\n                    patternErrorMessage: ( localize(3097, 'Super types should be in the form letterOrDigit[_-letterOrDigit]*')),\n                },\n                description: {\n                    type: 'string',\n                    description: ( localize(3098, 'The description of the semantic token type')),\n                }\n            }\n        }\n    }\n});\nconst tokenModifierExtPoint = ExtensionsRegistry.registerExtensionPoint({\n    extensionPoint: 'semanticTokenModifiers',\n    jsonSchema: {\n        description: ( localize(3099, 'Contributes semantic token modifiers.')),\n        type: 'array',\n        items: {\n            type: 'object',\n            properties: {\n                id: {\n                    type: 'string',\n                    description: ( localize(3100, 'The identifier of the semantic token modifier')),\n                    pattern: typeAndModifierIdPattern,\n                    patternErrorMessage: ( localize(3101, 'Identifiers should be in the form letterOrDigit[_-letterOrDigit]*'))\n                },\n                description: {\n                    type: 'string',\n                    description: ( localize(3102, 'The description of the semantic token modifier'))\n                }\n            }\n        }\n    }\n});\nconst tokenStyleDefaultsExtPoint = ExtensionsRegistry.registerExtensionPoint({\n    extensionPoint: 'semanticTokenScopes',\n    jsonSchema: {\n        description: ( localize(3103, 'Contributes semantic token scope maps.')),\n        type: 'array',\n        items: {\n            type: 'object',\n            properties: {\n                language: {\n                    description: ( localize(3104, 'Lists the languge for which the defaults are.')),\n                    type: 'string'\n                },\n                scopes: {\n                    description: ( localize(\n                        3105,\n                        'Maps a semantic token (described by semantic token selector) to one or more textMate scopes used to represent that token.'\n                    )),\n                    type: 'object',\n                    additionalProperties: {\n                        type: 'array',\n                        items: {\n                            type: 'string'\n                        }\n                    }\n                }\n            }\n        }\n    }\n});\nclass TokenClassificationExtensionPoints {\n    constructor() {\n        function validateTypeOrModifier(contribution, extensionPoint, collector) {\n            if (typeof contribution.id !== 'string' || contribution.id.length === 0) {\n                collector.error(( localize(\n                    3106,\n                    \"'configuration.{0}.id' must be defined and can not be empty\",\n                    extensionPoint\n                )));\n                return false;\n            }\n            if (!contribution.id.match(typeAndModifierIdPattern)) {\n                collector.error(( localize(\n                    3107,\n                    \"'configuration.{0}.id' must follow the pattern letterOrDigit[-_letterOrDigit]*\",\n                    extensionPoint\n                )));\n                return false;\n            }\n            const superType = contribution.superType;\n            if (superType && !superType.match(typeAndModifierIdPattern)) {\n                collector.error(( localize(\n                    3108,\n                    \"'configuration.{0}.superType' must follow the pattern letterOrDigit[-_letterOrDigit]*\",\n                    extensionPoint\n                )));\n                return false;\n            }\n            if (typeof contribution.description !== 'string' || contribution.id.length === 0) {\n                collector.error(( localize(\n                    3109,\n                    \"'configuration.{0}.description' must be defined and can not be empty\",\n                    extensionPoint\n                )));\n                return false;\n            }\n            return true;\n        }\n        tokenTypeExtPoint.setHandler((extensions, delta) => {\n            for (const extension of delta.added) {\n                const extensionValue = extension.value;\n                const collector = extension.collector;\n                if (!extensionValue || !Array.isArray(extensionValue)) {\n                    collector.error(( localize(3110, \"'configuration.semanticTokenType' must be an array\")));\n                    return;\n                }\n                for (const contribution of extensionValue) {\n                    if (validateTypeOrModifier(contribution, 'semanticTokenType', collector)) {\n                        tokenClassificationRegistry.registerTokenType(contribution.id, contribution.description, contribution.superType);\n                    }\n                }\n            }\n            for (const extension of delta.removed) {\n                const extensionValue = extension.value;\n                for (const contribution of extensionValue) {\n                    tokenClassificationRegistry.deregisterTokenType(contribution.id);\n                }\n            }\n        });\n        tokenModifierExtPoint.setHandler((extensions, delta) => {\n            for (const extension of delta.added) {\n                const extensionValue = extension.value;\n                const collector = extension.collector;\n                if (!extensionValue || !Array.isArray(extensionValue)) {\n                    collector.error(( localize(3111, \"'configuration.semanticTokenModifier' must be an array\")));\n                    return;\n                }\n                for (const contribution of extensionValue) {\n                    if (validateTypeOrModifier(contribution, 'semanticTokenModifier', collector)) {\n                        tokenClassificationRegistry.registerTokenModifier(contribution.id, contribution.description);\n                    }\n                }\n            }\n            for (const extension of delta.removed) {\n                const extensionValue = extension.value;\n                for (const contribution of extensionValue) {\n                    tokenClassificationRegistry.deregisterTokenModifier(contribution.id);\n                }\n            }\n        });\n        tokenStyleDefaultsExtPoint.setHandler((extensions, delta) => {\n            for (const extension of delta.added) {\n                const extensionValue = extension.value;\n                const collector = extension.collector;\n                if (!extensionValue || !Array.isArray(extensionValue)) {\n                    collector.error(( localize(3112, \"'configuration.semanticTokenScopes' must be an array\")));\n                    return;\n                }\n                for (const contribution of extensionValue) {\n                    if (contribution.language && typeof contribution.language !== 'string') {\n                        collector.error(( localize(3113, \"'configuration.semanticTokenScopes.language' must be a string\")));\n                        continue;\n                    }\n                    if (!contribution.scopes || typeof contribution.scopes !== 'object') {\n                        collector.error(( localize(\n                            3114,\n                            \"'configuration.semanticTokenScopes.scopes' must be defined as an object\"\n                        )));\n                        continue;\n                    }\n                    for (const selectorString in contribution.scopes) {\n                        const tmScopes = contribution.scopes[selectorString];\n                        if (!Array.isArray(tmScopes) || ( (tmScopes.some(l => typeof l !== 'string')))) {\n                            collector.error(( localize(\n                                3115,\n                                \"'configuration.semanticTokenScopes.scopes' values must be an array of strings\"\n                            )));\n                            continue;\n                        }\n                        try {\n                            const selector = tokenClassificationRegistry.parseTokenSelector(selectorString, contribution.language);\n                            tokenClassificationRegistry.registerTokenStyleDefault(selector, { scopesToProbe: ( (tmScopes.map(s => s.split(' ')))) });\n                        }\n                        catch (e) {\n                            collector.error(( localize(\n                                3116,\n                                \"configuration.semanticTokenScopes.scopes': Problems parsing selector {0}.\",\n                                selectorString\n                            )));\n                        }\n                    }\n                }\n            }\n            for (const extension of delta.removed) {\n                const extensionValue = extension.value;\n                for (const contribution of extensionValue) {\n                    for (const selectorString in contribution.scopes) {\n                        const tmScopes = contribution.scopes[selectorString];\n                        try {\n                            const selector = tokenClassificationRegistry.parseTokenSelector(selectorString, contribution.language);\n                            tokenClassificationRegistry.registerTokenStyleDefault(selector, { scopesToProbe: ( (tmScopes.map(s => s.split(' ')))) });\n                        }\n                        catch (e) {\n                        }\n                    }\n                }\n            }\n        });\n    }\n}\nlet TokenClassificationExtensionPointWorkbenchContribution = class TokenClassificationExtensionPointWorkbenchContribution {\n    static { this.ID = 'workbench.contrib.tokenClassificationExtensionPoint'; }\n    constructor(instantiationService) {\n        this.instantiationService = instantiationService;\n        this.instantiationService.createInstance(TokenClassificationExtensionPoints);\n    }\n};\nTokenClassificationExtensionPointWorkbenchContribution = ( (__decorate([\n    ( (__param(0, IInstantiationService)))\n], TokenClassificationExtensionPointWorkbenchContribution)));\nregisterWorkbenchContribution2(TokenClassificationExtensionPointWorkbenchContribution.ID, TokenClassificationExtensionPointWorkbenchContribution, 1 );\n\nexport { TokenClassificationExtensionPoints };\n","const isESM = true;\nclass LoaderStats {\n    static get() {\n        const amdLoadScript = ( new Map());\n        const amdInvokeFactory = ( new Map());\n        const nodeRequire = ( new Map());\n        const nodeEval = ( new Map());\n        function mark(map, stat) {\n            if (( map.has(stat.detail))) {\n                return;\n            }\n            map.set(stat.detail, -stat.timestamp);\n        }\n        function diff(map, stat) {\n            const duration = map.get(stat.detail);\n            if (!duration) {\n                return;\n            }\n            if (duration >= 0) {\n                return;\n            }\n            map.set(stat.detail, duration + stat.timestamp);\n        }\n        let stats = [];\n        if (typeof require === 'function' && typeof require.getStats === 'function') {\n            stats = require.getStats().slice(0).sort((a, b) => a.timestamp - b.timestamp);\n        }\n        for (const stat of stats) {\n            switch (stat.type) {\n                case 10 :\n                    mark(amdLoadScript, stat);\n                    break;\n                case 11 :\n                case 12 :\n                    diff(amdLoadScript, stat);\n                    break;\n                case 21 :\n                    mark(amdInvokeFactory, stat);\n                    break;\n                case 22 :\n                    diff(amdInvokeFactory, stat);\n                    break;\n                case 33 :\n                    mark(nodeRequire, stat);\n                    break;\n                case 34 :\n                    diff(nodeRequire, stat);\n                    break;\n                case 31 :\n                    mark(nodeEval, stat);\n                    break;\n                case 32 :\n                    diff(nodeEval, stat);\n                    break;\n            }\n        }\n        let nodeRequireTotal = 0;\n        nodeRequire.forEach(value => nodeRequireTotal += value);\n        function to2dArray(map) {\n            const res = [];\n            map.forEach((value, index) => res.push([index, value]));\n            return res;\n        }\n        return {\n            amdLoad: to2dArray(amdLoadScript),\n            amdInvoke: to2dArray(amdInvokeFactory),\n            nodeRequire: to2dArray(nodeRequire),\n            nodeEval: to2dArray(nodeEval),\n            nodeRequireTotal\n        };\n    }\n    static toMarkdownTable(header, rows) {\n        let result = '';\n        const lengths = [];\n        header.forEach((cell, ci) => {\n            lengths[ci] = cell.length;\n        });\n        rows.forEach(row => {\n            row.forEach((cell, ci) => {\n                if (typeof cell === 'undefined') {\n                    cell = row[ci] = '-';\n                }\n                const len = ( cell.toString()).length;\n                lengths[ci] = Math.max(len, lengths[ci]);\n            });\n        });\n        header.forEach((cell, ci) => { result += `| ${cell + ' '.repeat(lengths[ci] - ( cell.toString()).length)} `; });\n        result += '|\\n';\n        header.forEach((_cell, ci) => { result += `| ${'-'.repeat(lengths[ci])} `; });\n        result += '|\\n';\n        rows.forEach(row => {\n            row.forEach((cell, ci) => {\n                if (typeof cell !== 'undefined') {\n                    result += `| ${cell + ' '.repeat(lengths[ci] - ( cell.toString()).length)} `;\n                }\n            });\n            result += '|\\n';\n        });\n        return result;\n    }\n}\nexport { LoaderStats, isESM };\n","import n from '../../../../../../../../external/rollup-plugin-styles/dist/runtime/inject-css.js';\nvar css = \".token-inspect-widget{border:1px solid var(--vscode-editorHoverWidget-border);padding:10px;user-select:text;-webkit-user-select:text;z-index:50}.hc-black .tokens-inspect-widget,.hc-light .tokens-inspect-widget{border-width:2px}.monaco-editor .token-inspect-widget{background-color:var(--vscode-editorHoverWidget-background)}.monaco-editor .token-inspect-widget .tiw-metadata-separator{background-color:var(--vscode-editorHoverWidget-border)}.tiw-token{font-family:var(--monaco-monospace-font)}.tiw-metadata-separator{border:0;height:1px}.tiw-token-length{float:right;font-size:60%;font-weight:400}.tiw-metadata-table{width:100%}.tiw-metadata-value{font-family:var(--monaco-monospace-font);word-break:break-word}.tiw-metadata-values{list-style:none;margin-right:-10px;max-height:300px;overflow-y:auto;padding-left:0}.tiw-metadata-values>.tiw-metadata-value{margin-right:10px}.tiw-metadata-key{min-width:150px;padding-right:10px;vertical-align:top;white-space:nowrap;width:1px}.tiw-metadata-semantic{font-style:italic}.tiw-metadata-scopes{line-height:normal}.tiw-theme-selector{font-family:var(--monaco-monospace-font)}\";\nn(css,{});\nexport { css, css as default };\n","import { __decorate, __param } from '../../../../../../../../external/tslib/tslib.es6.js';\nimport './inspectEditorTokens.css.js';\nimport { localize } from '../../../../../nls.js';\nimport { clearNode, reset, append, isHTMLElement, $ as $$1 } from '../../../../../base/browser/dom.js';\nimport { Color } from '../../../../../base/common/color.js';\nimport { Disposable } from '../../../../../base/common/lifecycle.js';\nimport { registerEditorContribution, registerEditorAction, EditorAction } from '../../../../../editor/browser/editorExtensions.js';\nimport { Range } from '../../../../../editor/common/core/range.js';\nimport { TreeSitterTokenizationRegistry } from '../../../../../editor/common/languages.js';\nimport { TokenMetadata } from '../../../../../editor/common/encodedTokenAttributes.js';\nimport { ILanguageService } from '../../../../../editor/common/languages/language.js';\nimport { INotificationService } from '../../../../../platform/notification/common/notification.service.js';\nimport { findMatchingThemeRule } from '../../../../services/textMate/common/TMHelper.js';\nimport { ITextMateTokenizationService } from '../../../../services/textMate/browser/textMateTokenizationFeature.service.js';\nimport { IWorkbenchThemeService } from '../../../../services/themes/common/workbenchThemeService.service.js';\nimport { CancellationTokenSource } from '../../../../../base/common/cancellation.js';\nimport { SemanticTokenRule } from '../../../../../platform/theme/common/tokenClassificationRegistry.js';\nimport { IConfigurationService } from '../../../../../platform/configuration/common/configuration.service.js';\nimport { SEMANTIC_HIGHLIGHTING_SETTING_ID } from '../../../../../editor/contrib/semanticTokens/common/semanticTokensConfig.js';\nimport { Schemas } from '../../../../../base/common/network.js';\nimport { ILanguageFeaturesService } from '../../../../../editor/common/services/languageFeatures.js';\nimport { ITreeSitterParserService } from '../../../../../editor/common/services/treeSitterParserService.js';\nvar InspectEditorTokensController_1;\nconst $ = $$1;\nlet InspectEditorTokensController = class InspectEditorTokensController extends Disposable {\n    static { InspectEditorTokensController_1 = this; }\n    static { this.ID = 'editor.contrib.inspectEditorTokens'; }\n    static get(editor) {\n        return editor.getContribution(InspectEditorTokensController_1.ID);\n    }\n    constructor(editor, textMateService, treeSitterService, languageService, themeService, notificationService, configurationService, languageFeaturesService) {\n        super();\n        this._editor = editor;\n        this._textMateService = textMateService;\n        this._treeSitterService = treeSitterService;\n        this._themeService = themeService;\n        this._languageService = languageService;\n        this._notificationService = notificationService;\n        this._configurationService = configurationService;\n        this._languageFeaturesService = languageFeaturesService;\n        this._widget = null;\n        this._register(this._editor.onDidChangeModel((e) => this.stop()));\n        this._register(this._editor.onDidChangeModelLanguage((e) => this.stop()));\n        this._register(this._editor.onKeyUp((e) => e.keyCode === 9  && this.stop()));\n    }\n    dispose() {\n        this.stop();\n        super.dispose();\n    }\n    launch() {\n        if (this._widget) {\n            return;\n        }\n        if (!this._editor.hasModel()) {\n            return;\n        }\n        if (this._editor.getModel().uri.scheme === Schemas.vscodeNotebookCell) {\n            return;\n        }\n        this._widget = ( (new InspectEditorTokensWidget(\n            this._editor,\n            this._textMateService,\n            this._treeSitterService,\n            this._languageService,\n            this._themeService,\n            this._notificationService,\n            this._configurationService,\n            this._languageFeaturesService\n        )));\n    }\n    stop() {\n        if (this._widget) {\n            this._widget.dispose();\n            this._widget = null;\n        }\n    }\n    toggle() {\n        if (!this._widget) {\n            this.launch();\n        }\n        else {\n            this.stop();\n        }\n    }\n};\nInspectEditorTokensController = InspectEditorTokensController_1 = ( (__decorate([\n    ( (__param(1, ITextMateTokenizationService))),\n    ( (__param(2, ITreeSitterParserService))),\n    ( (__param(3, ILanguageService))),\n    ( (__param(4, IWorkbenchThemeService))),\n    ( (__param(5, INotificationService))),\n    ( (__param(6, IConfigurationService))),\n    ( (__param(7, ILanguageFeaturesService)))\n], InspectEditorTokensController)));\nclass InspectEditorTokens extends EditorAction {\n    constructor() {\n        super({\n            id: 'editor.action.inspectTMScopes',\n            label: ( localize(3117, \"Developer: Inspect Editor Tokens and Scopes\")),\n            alias: 'Developer: Inspect Editor Tokens and Scopes',\n            precondition: undefined\n        });\n    }\n    run(accessor, editor) {\n        const controller = InspectEditorTokensController.get(editor);\n        controller?.toggle();\n    }\n}\nfunction renderTokenText(tokenText) {\n    if (tokenText.length > 40) {\n        tokenText = tokenText.substr(0, 20) + '' + tokenText.substr(tokenText.length - 20);\n    }\n    let result = '';\n    for (let charIndex = 0, len = tokenText.length; charIndex < len; charIndex++) {\n        const charCode = tokenText.charCodeAt(charIndex);\n        switch (charCode) {\n            case 9 :\n                result += '\\u2192';\n                break;\n            case 32 :\n                result += '\\u00B7';\n                break;\n            default:\n                result += String.fromCharCode(charCode);\n        }\n    }\n    return result;\n}\nclass InspectEditorTokensWidget extends Disposable {\n    static { this._ID = 'editor.contrib.inspectEditorTokensWidget'; }\n    constructor(editor, textMateService, treeSitterService, languageService, themeService, notificationService, configurationService, languageFeaturesService) {\n        super();\n        this.allowEditorOverflow = true;\n        this._isDisposed = false;\n        this._editor = editor;\n        this._languageService = languageService;\n        this._themeService = themeService;\n        this._textMateService = textMateService;\n        this._treeSitterService = treeSitterService;\n        this._notificationService = notificationService;\n        this._configurationService = configurationService;\n        this._languageFeaturesService = languageFeaturesService;\n        this._model = this._editor.getModel();\n        this._domNode = document.createElement('div');\n        this._domNode.className = 'token-inspect-widget';\n        this._currentRequestCancellationTokenSource = ( (new CancellationTokenSource()));\n        this._beginCompute(this._editor.getPosition());\n        this._register(this._editor.onDidChangeCursorPosition((e) => this._beginCompute(this._editor.getPosition())));\n        this._register(themeService.onDidColorThemeChange(_ => this._beginCompute(this._editor.getPosition())));\n        this._register(configurationService.onDidChangeConfiguration(e => e.affectsConfiguration('editor.semanticHighlighting.enabled') && this._beginCompute(this._editor.getPosition())));\n        this._editor.addContentWidget(this);\n    }\n    dispose() {\n        this._isDisposed = true;\n        this._editor.removeContentWidget(this);\n        this._currentRequestCancellationTokenSource.cancel();\n        super.dispose();\n    }\n    getId() {\n        return InspectEditorTokensWidget._ID;\n    }\n    _beginCompute(position) {\n        const grammar = this._textMateService.createTokenizer(this._model.getLanguageId());\n        const semanticTokens = this._computeSemanticTokens(position);\n        const tree = this._treeSitterService.getParseResult(this._model);\n        clearNode(this._domNode);\n        this._domNode.appendChild(document.createTextNode(( localize(3118, \"Loading...\"))));\n        Promise.all([grammar, semanticTokens]).then(([grammar, semanticTokens]) => {\n            if (this._isDisposed) {\n                return;\n            }\n            this._compute(grammar, semanticTokens, tree?.tree, position);\n            this._domNode.style.maxWidth = `${Math.max(this._editor.getLayoutInfo().width * 0.66, 500)}px`;\n            this._editor.layoutContentWidget(this);\n        }, (err) => {\n            this._notificationService.warn(err);\n            setTimeout(() => {\n                InspectEditorTokensController.get(this._editor)?.stop();\n            });\n        });\n    }\n    _isSemanticColoringEnabled() {\n        const setting = this._configurationService.getValue(SEMANTIC_HIGHLIGHTING_SETTING_ID, { overrideIdentifier: this._model.getLanguageId(), resource: this._model.uri })?.enabled;\n        if (typeof setting === 'boolean') {\n            return setting;\n        }\n        return this._themeService.getColorTheme().semanticHighlighting;\n    }\n    _compute(grammar, semanticTokens, tree, position) {\n        const textMateTokenInfo = grammar && this._getTokensAtPosition(grammar, position);\n        const semanticTokenInfo = semanticTokens && this._getSemanticTokenAtPosition(semanticTokens, position);\n        const treeSitterTokenInfo = tree && this._getTreeSitterTokenAtPosition(tree, position);\n        if (!textMateTokenInfo && !semanticTokenInfo && !treeSitterTokenInfo) {\n            reset(this._domNode, 'No grammar or semantic tokens available.');\n            return;\n        }\n        const tmMetadata = textMateTokenInfo?.metadata;\n        const semMetadata = semanticTokenInfo?.metadata;\n        const semTokenText = semanticTokenInfo && renderTokenText(this._model.getValueInRange(semanticTokenInfo.range));\n        const tmTokenText = textMateTokenInfo && renderTokenText(this._model.getLineContent(position.lineNumber).substring(textMateTokenInfo.token.startIndex, textMateTokenInfo.token.endIndex));\n        const tokenText = semTokenText || tmTokenText || '';\n        reset(this._domNode, $('h2.tiw-token', undefined, tokenText, $('span.tiw-token-length', undefined, `${tokenText.length} ${tokenText.length === 1 ? 'char' : 'chars'}`)));\n        append(this._domNode, $('hr.tiw-metadata-separator', { 'style': 'clear:both' }));\n        append(this._domNode, $('table.tiw-metadata-table', undefined, $('tbody', undefined, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'language'), $('td.tiw-metadata-value', undefined, tmMetadata?.languageId || '')), $('tr', undefined, $('td.tiw-metadata-key', undefined, 'standard token type'), $('td.tiw-metadata-value', undefined, this._tokenTypeToString(tmMetadata?.tokenType || 0 ))), ...this._formatMetadata(semMetadata, tmMetadata))));\n        if (semanticTokenInfo) {\n            append(this._domNode, $('hr.tiw-metadata-separator'));\n            const table = append(this._domNode, $('table.tiw-metadata-table', undefined));\n            const tbody = append(table, $('tbody', undefined, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'semantic token type'), $('td.tiw-metadata-value', undefined, semanticTokenInfo.type))));\n            if (semanticTokenInfo.modifiers.length) {\n                append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'modifiers'), $('td.tiw-metadata-value', undefined, semanticTokenInfo.modifiers.join(' '))));\n            }\n            if (semanticTokenInfo.metadata) {\n                const properties = ['foreground', 'bold', 'italic', 'underline', 'strikethrough'];\n                const propertiesByDefValue = {};\n                const allDefValues = ( (new Array()));\n                for (const property of properties) {\n                    if (semanticTokenInfo.metadata[property] !== undefined) {\n                        const definition = semanticTokenInfo.definitions[property];\n                        const defValue = this._renderTokenStyleDefinition(definition, property);\n                        const defValueStr = ( (defValue.map(el => isHTMLElement(el) ? el.outerHTML : el))).join();\n                        let properties = propertiesByDefValue[defValueStr];\n                        if (!properties) {\n                            propertiesByDefValue[defValueStr] = properties = [];\n                            allDefValues.push([defValue, defValueStr]);\n                        }\n                        properties.push(property);\n                    }\n                }\n                for (const [defValue, defValueStr] of allDefValues) {\n                    append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, propertiesByDefValue[defValueStr].join(', ')), $('td.tiw-metadata-value', undefined, ...defValue)));\n                }\n            }\n        }\n        if (textMateTokenInfo) {\n            const theme = this._themeService.getColorTheme();\n            append(this._domNode, $('hr.tiw-metadata-separator'));\n            const table = append(this._domNode, $('table.tiw-metadata-table'));\n            const tbody = append(table, $('tbody'));\n            if (tmTokenText && tmTokenText !== tokenText) {\n                append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'textmate token'), $('td.tiw-metadata-value', undefined, `${tmTokenText} (${tmTokenText.length})`)));\n            }\n            const scopes = ( (new Array()));\n            for (let i = textMateTokenInfo.token.scopes.length - 1; i >= 0; i--) {\n                scopes.push(textMateTokenInfo.token.scopes[i]);\n                if (i > 0) {\n                    scopes.push($('br'));\n                }\n            }\n            append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'textmate scopes'), $('td.tiw-metadata-value.tiw-metadata-scopes', undefined, ...scopes)));\n            const matchingRule = findMatchingThemeRule(theme, textMateTokenInfo.token.scopes, false);\n            const semForeground = semanticTokenInfo?.metadata?.foreground;\n            if (matchingRule) {\n                if (semForeground !== textMateTokenInfo.metadata.foreground) {\n                    let defValue = $('code.tiw-theme-selector', undefined, matchingRule.rawSelector, $('br'), JSON.stringify(matchingRule.settings, null, '\\t'));\n                    if (semForeground) {\n                        defValue = $('s', undefined, defValue);\n                    }\n                    append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'foreground'), $('td.tiw-metadata-value', undefined, defValue)));\n                }\n            }\n            else if (!semForeground) {\n                append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'foreground'), $('td.tiw-metadata-value', undefined, 'No theme selector')));\n            }\n        }\n        if (treeSitterTokenInfo) {\n            append(this._domNode, $('hr.tiw-metadata-separator'));\n            const table = append(this._domNode, $('table.tiw-metadata-table'));\n            const tbody = append(table, $('tbody'));\n            append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'tree-sitter token'), $('td.tiw-metadata-value', undefined, `${treeSitterTokenInfo.text}`)));\n            const scopes = ( (new Array()));\n            let node = treeSitterTokenInfo;\n            while (node.parent) {\n                scopes.push(node.type);\n                node = node.parent;\n                if (node) {\n                    scopes.push($('br'));\n                }\n            }\n            append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'tree-sitter scopes'), $('td.tiw-metadata-value.tiw-metadata-scopes', undefined, ...scopes)));\n            const tokenizationSupport = TreeSitterTokenizationRegistry.get(this._model.getLanguageId());\n            const captures = tokenizationSupport?.captureAtPosition(position.lineNumber, position.column, this._model);\n            if (captures && captures.length > 0) {\n                append(tbody, $('tr', undefined, $('td.tiw-metadata-key', undefined, 'foreground'), $('td.tiw-metadata-value', undefined, captures[captures.length - 1].name)));\n            }\n        }\n    }\n    _formatMetadata(semantic, tm) {\n        const elements = ( (new Array()));\n        function render(property) {\n            const value = semantic?.[property] || tm?.[property];\n            if (value !== undefined) {\n                const semanticStyle = semantic?.[property] ? 'tiw-metadata-semantic' : '';\n                elements.push($('tr', undefined, $('td.tiw-metadata-key', undefined, property), $(`td.tiw-metadata-value.${semanticStyle}`, undefined, value)));\n            }\n            return value;\n        }\n        const foreground = render('foreground');\n        const background = render('background');\n        if (foreground && background) {\n            const backgroundColor = ( (Color.fromHex(background))), foregroundColor = ( (Color.fromHex(foreground)));\n            if (backgroundColor.isOpaque()) {\n                elements.push($('tr', undefined, $('td.tiw-metadata-key', undefined, 'contrast ratio'), $('td.tiw-metadata-value', undefined, backgroundColor.getContrastRatio(foregroundColor.makeOpaque(backgroundColor)).toFixed(2))));\n            }\n            else {\n                elements.push($('tr', undefined, $('td.tiw-metadata-key', undefined, 'Contrast ratio cannot be precise for background colors that use transparency'), $('td.tiw-metadata-value')));\n            }\n        }\n        const fontStyleLabels = ( (new Array()));\n        function addStyle(key) {\n            let label;\n            if (semantic && semantic[key]) {\n                label = $('span.tiw-metadata-semantic', undefined, key);\n            }\n            else if (tm && tm[key]) {\n                label = key;\n            }\n            if (label) {\n                if (fontStyleLabels.length) {\n                    fontStyleLabels.push(' ');\n                }\n                fontStyleLabels.push(label);\n            }\n        }\n        addStyle('bold');\n        addStyle('italic');\n        addStyle('underline');\n        addStyle('strikethrough');\n        if (fontStyleLabels.length) {\n            elements.push($('tr', undefined, $('td.tiw-metadata-key', undefined, 'font style'), $('td.tiw-metadata-value', undefined, ...fontStyleLabels)));\n        }\n        return elements;\n    }\n    _decodeMetadata(metadata) {\n        const colorMap = this._themeService.getColorTheme().tokenColorMap;\n        const languageId = TokenMetadata.getLanguageId(metadata);\n        const tokenType = TokenMetadata.getTokenType(metadata);\n        const fontStyle = TokenMetadata.getFontStyle(metadata);\n        const foreground = TokenMetadata.getForeground(metadata);\n        const background = TokenMetadata.getBackground(metadata);\n        return {\n            languageId: this._languageService.languageIdCodec.decodeLanguageId(languageId),\n            tokenType: tokenType,\n            bold: ((fontStyle & 2) ) ? true : undefined,\n            italic: ((fontStyle & 1) ) ? true : undefined,\n            underline: ((fontStyle & 4) ) ? true : undefined,\n            strikethrough: ((fontStyle & 8) ) ? true : undefined,\n            foreground: colorMap[foreground],\n            background: colorMap[background]\n        };\n    }\n    _tokenTypeToString(tokenType) {\n        switch (tokenType) {\n            case 0 : return 'Other';\n            case 1 : return 'Comment';\n            case 2 : return 'String';\n            case 3 : return 'RegEx';\n            default: return '??';\n        }\n    }\n    _getTokensAtPosition(grammar, position) {\n        const lineNumber = position.lineNumber;\n        const stateBeforeLine = this._getStateBeforeLine(grammar, lineNumber);\n        const tokenizationResult1 = grammar.tokenizeLine(this._model.getLineContent(lineNumber), stateBeforeLine);\n        const tokenizationResult2 = grammar.tokenizeLine2(this._model.getLineContent(lineNumber), stateBeforeLine);\n        let token1Index = 0;\n        for (let i = tokenizationResult1.tokens.length - 1; i >= 0; i--) {\n            const t = tokenizationResult1.tokens[i];\n            if (position.column - 1 >= t.startIndex) {\n                token1Index = i;\n                break;\n            }\n        }\n        let token2Index = 0;\n        for (let i = (tokenizationResult2.tokens.length >>> 1); i >= 0; i--) {\n            if (position.column - 1 >= tokenizationResult2.tokens[(i << 1)]) {\n                token2Index = i;\n                break;\n            }\n        }\n        return {\n            token: tokenizationResult1.tokens[token1Index],\n            metadata: this._decodeMetadata(tokenizationResult2.tokens[(token2Index << 1) + 1])\n        };\n    }\n    _getStateBeforeLine(grammar, lineNumber) {\n        let state = null;\n        for (let i = 1; i < lineNumber; i++) {\n            const tokenizationResult = grammar.tokenizeLine(this._model.getLineContent(i), state);\n            state = tokenizationResult.ruleStack;\n        }\n        return state;\n    }\n    isSemanticTokens(token) {\n        return token && token.data;\n    }\n    async _computeSemanticTokens(position) {\n        if (!this._isSemanticColoringEnabled()) {\n            return null;\n        }\n        const tokenProviders = this._languageFeaturesService.documentSemanticTokensProvider.ordered(this._model);\n        if (tokenProviders.length) {\n            const provider = tokenProviders[0];\n            const tokens = await Promise.resolve(provider.provideDocumentSemanticTokens(this._model, null, this._currentRequestCancellationTokenSource.token));\n            if (this.isSemanticTokens(tokens)) {\n                return { tokens, legend: provider.getLegend() };\n            }\n        }\n        const rangeTokenProviders = this._languageFeaturesService.documentRangeSemanticTokensProvider.ordered(this._model);\n        if (rangeTokenProviders.length) {\n            const provider = rangeTokenProviders[0];\n            const lineNumber = position.lineNumber;\n            const range = ( (new Range(lineNumber, 1, lineNumber, this._model.getLineMaxColumn(lineNumber))));\n            const tokens = await Promise.resolve(provider.provideDocumentRangeSemanticTokens(this._model, range, this._currentRequestCancellationTokenSource.token));\n            if (this.isSemanticTokens(tokens)) {\n                return { tokens, legend: provider.getLegend() };\n            }\n        }\n        return null;\n    }\n    _getSemanticTokenAtPosition(semanticTokens, pos) {\n        const tokenData = semanticTokens.tokens.data;\n        const defaultLanguage = this._model.getLanguageId();\n        let lastLine = 0;\n        let lastCharacter = 0;\n        const posLine = pos.lineNumber - 1, posCharacter = pos.column - 1;\n        for (let i = 0; i < tokenData.length; i += 5) {\n            const lineDelta = tokenData[i], charDelta = tokenData[i + 1], len = tokenData[i + 2], typeIdx = tokenData[i + 3], modSet = tokenData[i + 4];\n            const line = lastLine + lineDelta;\n            const character = lineDelta === 0 ? lastCharacter + charDelta : charDelta;\n            if (posLine === line && character <= posCharacter && posCharacter < character + len) {\n                const type = semanticTokens.legend.tokenTypes[typeIdx] || 'not in legend (ignored)';\n                const modifiers = [];\n                let modifierSet = modSet;\n                for (let modifierIndex = 0; modifierSet > 0 && modifierIndex < semanticTokens.legend.tokenModifiers.length; modifierIndex++) {\n                    if (modifierSet & 1) {\n                        modifiers.push(semanticTokens.legend.tokenModifiers[modifierIndex]);\n                    }\n                    modifierSet = modifierSet >> 1;\n                }\n                if (modifierSet > 0) {\n                    modifiers.push('not in legend (ignored)');\n                }\n                const range = ( (new Range(line + 1, character + 1, line + 1, character + 1 + len)));\n                const definitions = {};\n                const colorMap = this._themeService.getColorTheme().tokenColorMap;\n                const theme = this._themeService.getColorTheme();\n                const tokenStyle = theme.getTokenStyleMetadata(type, modifiers, defaultLanguage, true, definitions);\n                let metadata = undefined;\n                if (tokenStyle) {\n                    metadata = {\n                        languageId: undefined,\n                        tokenType: 0 ,\n                        bold: tokenStyle?.bold,\n                        italic: tokenStyle?.italic,\n                        underline: tokenStyle?.underline,\n                        strikethrough: tokenStyle?.strikethrough,\n                        foreground: colorMap[tokenStyle?.foreground || 0 ],\n                        background: undefined\n                    };\n                }\n                return { type, modifiers, range, metadata, definitions };\n            }\n            lastLine = line;\n            lastCharacter = character;\n        }\n        return null;\n    }\n    _walkTreeforPosition(cursor, pos) {\n        const offset = this._model.getOffsetAt(pos);\n        cursor.gotoFirstChild();\n        let goChild = false;\n        let lastGoodNode = null;\n        do {\n            if (cursor.currentNode.startIndex <= offset && offset < cursor.currentNode.endIndex) {\n                goChild = true;\n                lastGoodNode = cursor.currentNode;\n            }\n            else {\n                goChild = false;\n            }\n        } while (goChild ? cursor.gotoFirstChild() : cursor.gotoNextSibling());\n        return lastGoodNode;\n    }\n    _getTreeSitterTokenAtPosition(tree, pos) {\n        const cursor = tree.walk();\n        return this._walkTreeforPosition(cursor, pos);\n    }\n    _renderTokenStyleDefinition(definition, property) {\n        const elements = ( (new Array()));\n        if (definition === undefined) {\n            return elements;\n        }\n        const theme = this._themeService.getColorTheme();\n        if (Array.isArray(definition)) {\n            const scopesDefinition = {};\n            theme.resolveScopes(definition, scopesDefinition);\n            const matchingRule = scopesDefinition[property];\n            if (matchingRule && scopesDefinition.scope) {\n                const scopes = $('ul.tiw-metadata-values');\n                const strScopes = Array.isArray(matchingRule.scope) ? matchingRule.scope : [String(matchingRule.scope)];\n                for (const strScope of strScopes) {\n                    scopes.appendChild($('li.tiw-metadata-value.tiw-metadata-scopes', undefined, strScope));\n                }\n                elements.push(scopesDefinition.scope.join(' '), scopes, $('code.tiw-theme-selector', undefined, JSON.stringify(matchingRule.settings, null, '\\t')));\n                return elements;\n            }\n            return elements;\n        }\n        else if (SemanticTokenRule.is(definition)) {\n            const scope = theme.getTokenStylingRuleScope(definition);\n            if (scope === 'setting') {\n                elements.push(`User settings: ${definition.selector.id} - ${this._renderStyleProperty(definition.style, property)}`);\n                return elements;\n            }\n            else if (scope === 'theme') {\n                elements.push(`Color theme: ${definition.selector.id} - ${this._renderStyleProperty(definition.style, property)}`);\n                return elements;\n            }\n            return elements;\n        }\n        else {\n            const style = theme.resolveTokenStyleValue(definition);\n            elements.push(`Default: ${style ? this._renderStyleProperty(style, property) : ''}`);\n            return elements;\n        }\n    }\n    _renderStyleProperty(style, property) {\n        switch (property) {\n            case 'foreground': return style.foreground ? Color.Format.CSS.formatHexA(style.foreground, true) : '';\n            default: return style[property] !== undefined ? String(style[property]) : '';\n        }\n    }\n    getDomNode() {\n        return this._domNode;\n    }\n    getPosition() {\n        return {\n            position: this._editor.getPosition(),\n            preference: [2 , 1 ]\n        };\n    }\n}\nregisterEditorContribution(InspectEditorTokensController.ID, InspectEditorTokensController, 4 );\nregisterEditorAction(InspectEditorTokens);\nexport { InspectEditorTokensController };\n","import { localize } from '../../../../nls.js';\nimport { ExtensionsRegistry } from '../../extensions/common/extensionsRegistry.js';\nimport { languagesExtPoint } from '../../language/common/languageService.js';\nconst grammarsExtPoint = ExtensionsRegistry.registerExtensionPoint({\n    extensionPoint: 'grammars',\n    deps: [languagesExtPoint],\n    jsonSchema: {\n        description: ( localize(7063, 'Contributes textmate tokenizers.')),\n        type: 'array',\n        defaultSnippets: [{ body: [{ language: '${1:id}', scopeName: 'source.${2:id}', path: './syntaxes/${3:id}.tmLanguage.' }] }],\n        items: {\n            type: 'object',\n            defaultSnippets: [{ body: { language: '${1:id}', scopeName: 'source.${2:id}', path: './syntaxes/${3:id}.tmLanguage.' } }],\n            properties: {\n                language: {\n                    description: ( localize(7064, 'Language identifier for which this syntax is contributed to.')),\n                    type: 'string'\n                },\n                scopeName: {\n                    description: ( localize(7065, 'Textmate scope name used by the tmLanguage file.')),\n                    type: 'string'\n                },\n                path: {\n                    description: ( localize(\n                        7066,\n                        'Path of the tmLanguage file. The path is relative to the extension folder and typically starts with \\'./syntaxes/\\'.'\n                    )),\n                    type: 'string'\n                },\n                embeddedLanguages: {\n                    description: ( localize(\n                        7067,\n                        'A map of scope name to language id if this grammar contains embedded languages.'\n                    )),\n                    type: 'object'\n                },\n                tokenTypes: {\n                    description: ( localize(7068, 'A map of scope name to token types.')),\n                    type: 'object',\n                    additionalProperties: {\n                        enum: ['string', 'comment', 'other']\n                    }\n                },\n                injectTo: {\n                    description: ( localize(7069, 'List of language scope names to which this grammar is injected to.')),\n                    type: 'array',\n                    items: {\n                        type: 'string'\n                    }\n                },\n                balancedBracketScopes: {\n                    description: ( localize(7070, 'Defines which scope names contain balanced brackets.')),\n                    type: 'array',\n                    items: {\n                        type: 'string'\n                    },\n                    default: ['*'],\n                },\n                unbalancedBracketScopes: {\n                    description: ( localize(7071, 'Defines which scope names do not contain balanced brackets.')),\n                    type: 'array',\n                    items: {\n                        type: 'string'\n                    },\n                    default: [],\n                },\n            },\n            required: ['scopeName', 'path']\n        }\n    }\n});\nexport { grammarsExtPoint };\n"],"names":[],"sourceRoot":""}