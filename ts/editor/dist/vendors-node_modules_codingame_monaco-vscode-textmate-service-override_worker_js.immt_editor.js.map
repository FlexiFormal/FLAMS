{"version":3,"file":"vendors-node_modules_codingame_monaco-vscode-textmate-service-override_worker_js.immt_editor.js","mappings":";;;;;;;;;;;AAAgE;AACkC;;AAElG,gHAAqB,CAAC,yEAAM;;;;;;;;;;;;;;;;;;;;ACH2B;AACgB;AACA;AACV;;AAE7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sEAAkB;AACvC;AACA;AACA;AACA;AACA,0BAA0B,iEAAG;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,qCAAqC,gOAAyB;AAC9D,sCAAsC,mOAA0B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,qBAAqB,yEAAgB;AACrC,kCAAkC;AAClC;AACA;AACA,SAAS;AACT;AACA;AACA,oBAAoB,iEAAG;AACvB;AACA,kDAAkD,gFAAuB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE8C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9FwB;AACiB;AAC1C;AACD;AACwB;AACH;AACA;AACd;AACY;AACK;AACM;AACa;AACQ;AAC2B;AAC5C;AACyB;AACU;;AAEjH,sCAAsC,kGAAe;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,qGAAe;AACzD,wCAAwC,gFAAgB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,qFAAS;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,uHAAgC,gCAAgC,6GAA2B;AACzI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,gBAAgB,8EAAU;AAC1B,kDAAkD,0GAAuB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB,QAAQ,gOAAyB;AAC5E;AACA;AACA;AACA;AACA;AACA,uCAAuC,qIAAgC;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yFAAU;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,kFAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,uDAAuD;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;;AAEmC;;;;;;;;;;;;;ACpJG;;;;;;;;;;;;;ACA+F;;;;;;;;;;;;;;;;ACA9E;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,gEAAkB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACiC;;;;;;;;;;;;;;;ACtBjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAsB;AACrD;AACA,0CAA0C;AAC1C;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gBAAgB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACyB;;;;;;;;;;;;;;;;;;ACvE8D;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6DAAkB,QAAQ,gDAAK;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oEAAyB;AAC1C;AACwD;;;;;;;;;;;;;;;;ACtBK;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA;AACA,sBAAsB,mEAAW;AACjC;AACA;AACA;AACA;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACsB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3D4C;AACqB;AACxB;AACD;AACb;AACA;AACI;AACc;AACtB;AACoD;AAC5C;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,8DAAU;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,8DAAU;AACrD;AACA;AACA;AACA,qCAAqC,8DAAU;AAC/C,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,+CAA+C,6BAA6B;AAC5E;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,qCAAqC,mCAAmC;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,6DAAW;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAAkB;AAC1C;AACA;AACA;AACA;AACA,6DAA6D,6DAAW;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,6DAAW;AAC7E;AACA;AACA;AACA,+BAA+B,6DAAQ;AACvC,oCAAoC,yDAAS;AAC7C;AACA;AACA;AACA,yDAAyD,6DAAW;AACpE;AACA,0CAA0C;AAC1C;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAAkB;AAC1C;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,oCAAoC,sDAAU;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,6DAAQ;AACvC,oCAAoC,yDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAW;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6DAAW;AACzD;AACA;AACA;AACA;AACA,8CAA8C,6DAAW;AACzD;AACA;AACA,sDAAsD,6DAAW,6BAA6B,6DAAW;AACzG;AACA;AACA;AACA;AACA;AACA,QAAQ,6DAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yBAAyB;AAC/D;AACA;AACA;AACA,mCAAmC,6DAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,6DAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,yEAAiB;AAC7B;AACA;AACA;AACA,YAAY,+EAAmB;AAC/B;AACA,IAAI,8DAAU;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAiB;AACzB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,qEAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yGAAgC;AAC9D,mBAAmB,gEAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0EAA0E,yDAAS;AACnF;AACA;AACoL;;;;;;;;;;;;;;;;;;;;;AClavH;AACgB;AAC9B;AACE;AACsB;AACtB;AACjD;AACA;AACA;AACA,gCAAgC,oEAAY;AAC5C;AACA,sBAAsB,oEAAY;AAClC;AACA;AACA,wBAAwB,WAAW;AACnC,8BAA8B,oEAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAa;AACrB;AACA,QAAQ,qEAAa;AACrB;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA,YAAY,qEAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,6DAAQ;AACpD;AACA,qCAAqC,uDAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,gFAAuB;AAClE;AACA;AACA;AACA,2CAA2C,gFAAuB;AAClE;AACA,uCAAuC,gFAAuB;AAC9D,+CAA+C,gFAAuB;AACtE;AACA;AACA;AACA,+CAA+C,gFAAuB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,gFAAuB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,gFAAuB;AAC7D;AACA;AACA,kCAAkC,gFAAuB;AACzD,kCAAkC,gFAAuB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA;AACA,uBAAuB,mEAAW;AAClC;AACA;AACqC;;;;;;;;;;;;;;;;;ACvJwC;AACF;AAC3E;AACA;AACA;AACA,sBAAsB,oEAAY;AAClC;AACA;AACA,wBAAwB,WAAW;AACnC,qBAAqB,oFAAyB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,oFAAyB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAa;AACrB;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AAC4C;;;;;;;;;;;;;;;;;;ACpDC;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,sDAAU;AACzC;AACA;AACA;AACA;AACA,yCAAyC,iBAAiB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,0BAA0B;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,0BAA0B;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACqE;;;;;;;;;;;;;;;;;;;ACpHR;AACR;AACD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,6BAA6B;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,qEAAa;AACxC;AACA;AACA;AACA;AACA,eAAe,qEAAa;AAC5B;AACA;AACA;AACA,eAAe,qEAAa;AAC5B;AACA;AACA;AACA,eAAe,qEAAa;AAC5B;AACA;AACA;AACA,eAAe,qEAAa;AAC5B;AACA;AACA;AACA,eAAe,qEAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6DAAiB;AAC/C;AACA;AACA,+CAA+C,6BAA6B;AAC5E,qCAAqC,6DAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,yBAAyB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,SAAS;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,8BAA8B;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACsD;;;;;;;;;;;;;;;;;;AChSD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,6DAAW;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACoD;;;;;;;SCpDpD;SACA;;SAEA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;SACA;;SAEA;SACA;;SAEA;SACA;SACA;;SAEA;SACA;;;;;UCzBA;UACA;UACA;UACA;UACA,+BAA+B,wCAAwC;UACvE;UACA;UACA;UACA;UACA,iBAAiB,qBAAqB;UACtC;UACA;UACA,kBAAkB,qBAAqB;UACvC;UACA;UACA,KAAK;UACL;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;;;;UC3BA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA,sDAAsD;UACtD,sCAAsC,iEAAiE;UACvG;UACA;UACA;UACA;UACA;UACA;;;;;UCzBA;UACA;UACA;UACA;UACA,yCAAyC,wCAAwC;UACjF;UACA;UACA;;;;;UCPA;UACA;UACA;UACA;UACA;UACA;UACA;UACA,EAAE;UACF;;;;;UCRA;UACA;UACA;UACA;UACA;;;;;UCJA;;;;;UCAA;UACA;UACA;UACA,uDAAuD,iBAAiB;UACxE;UACA,gDAAgD,aAAa;UAC7D;;;;;UCNA;;UAEA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA,MAAM,uBAAuB;UAC7B;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA,MAAM,gBAAgB;UACtB;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;UACA;UACA,iCAAiC;;UAEjC;UACA;UACA;UACA,KAAK;UACL,eAAe;UACf;UACA;UACA;UACA;UACA,MAAM;UACN;UACA;UACA;UACA;UACA;UACA;;UAEA;;UAEA;;UAEA;;UAEA;;;;;SE1DA;SACA;SACA;SACA;SACA","sources":["webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.worker.esm.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.worker.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateWorkerTokenizer.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/worker.js","webpack://immt-editor/./node_modules/@codingame/monaco-vscode-textmate-service-override/workers/textmate.worker.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/base/common/worker/simpleWorkerBootstrap.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/encodedTokenAttributes.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/languages/nullTokenize.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/model/fixedArray.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/model/textModelTokens.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/tokens/contiguousMultilineTokens.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/tokens/contiguousMultilineTokensBuilder.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/tokens/contiguousTokensEditing.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/tokens/lineTokens.js","webpack://immt-editor/./node_modules/vscode/vscode/src/vs/editor/common/tokens/tokenArray.js","webpack://immt-editor/webpack/bootstrap","webpack://immt-editor/webpack/runtime/chunk loaded","webpack://immt-editor/webpack/runtime/create fake namespace object","webpack://immt-editor/webpack/runtime/define property getters","webpack://immt-editor/webpack/runtime/ensure chunk","webpack://immt-editor/webpack/runtime/get javascript chunk filename","webpack://immt-editor/webpack/runtime/hasOwnProperty shorthand","webpack://immt-editor/webpack/runtime/make namespace object","webpack://immt-editor/webpack/runtime/import chunk loading","webpack://immt-editor/webpack/before-startup","webpack://immt-editor/webpack/startup","webpack://immt-editor/webpack/after-startup"],"sourcesContent":["import { create } from './textMateTokenizationWorker.worker.js';\nimport { bootstrapSimpleWorker } from 'vscode/vscode/vs/base/common/worker/simpleWorkerBootstrap';\n\nbootstrapSimpleWorker(create);\n","import { URI } from 'vscode/vscode/vs/base/common/uri';\nimport { TMGrammarFactory } from '../../../common/TMGrammarFactory.js';\nimport { TextMateWorkerTokenizer } from './textMateWorkerTokenizer.js';\nimport { TextMateWorkerHost } from './textMateWorkerHost.js';\n\nfunction create(workerServer) {\n    return ( new TextMateTokenizationWorker(workerServer));\n}\nclass TextMateTokenizationWorker {\n    constructor(workerServer) {\n        this._models = ( new Map());\n        this._grammarCache = [];\n        this._grammarFactory = Promise.resolve(null);\n        this._host = TextMateWorkerHost.getChannel(workerServer);\n    }\n    async $init(_createData) {\n        const grammarDefinitions = ( _createData.grammarDefinitions.map((def) => {\n            return {\n                location: URI.revive(def.location),\n                language: def.language,\n                scopeName: def.scopeName,\n                embeddedLanguages: def.embeddedLanguages,\n                tokenTypes: def.tokenTypes,\n                injectTo: def.injectTo,\n                balancedBracketSelectors: def.balancedBracketSelectors,\n                unbalancedBracketSelectors: def.unbalancedBracketSelectors,\n                sourceExtensionId: def.sourceExtensionId,\n            };\n        }));\n        this._grammarFactory = this._loadTMGrammarFactory(grammarDefinitions, _createData.onigurumaWASMUri);\n    }\n    async _loadTMGrammarFactory(grammarDefinitions, onigurumaWASMUri) {\n        const vscodeTextmate = await import('vscode-textmate').then(module => module.default ?? module);\n        const vscodeOniguruma = await import('vscode-oniguruma').then(module => module.default ?? module);\n        const response = await fetch(onigurumaWASMUri);\n        const bytes = await response.arrayBuffer();\n        await vscodeOniguruma.loadWASM(bytes);\n        const onigLib = Promise.resolve({\n            createOnigScanner: (sources) => vscodeOniguruma.createOnigScanner(sources),\n            createOnigString: (str) => vscodeOniguruma.createOnigString(str)\n        });\n        return ( new TMGrammarFactory({\n            logTrace: (msg) => { },\n            logError: (msg, err) => console.error(msg, err),\n            readFile: (resource) => this._host.$readFile(resource)\n        }, grammarDefinitions, vscodeTextmate, onigLib));\n    }\n    $acceptNewModel(data) {\n        const uri = URI.revive(data.uri);\n        const that = this;\n        this._models.set(data.controllerId, ( new TextMateWorkerTokenizer(uri, data.lines, data.EOL, data.versionId, {\n            async getOrCreateGrammar(languageId, encodedLanguageId) {\n                const grammarFactory = await that._grammarFactory;\n                if (!grammarFactory) {\n                    return Promise.resolve(null);\n                }\n                if (!that._grammarCache[encodedLanguageId]) {\n                    that._grammarCache[encodedLanguageId] = grammarFactory.createGrammar(languageId, encodedLanguageId);\n                }\n                return that._grammarCache[encodedLanguageId];\n            },\n            setTokensAndStates(versionId, tokens, stateDeltas) {\n                that._host.$setTokensAndStates(data.controllerId, versionId, tokens, stateDeltas);\n            },\n            reportTokenizationTime(timeMs, languageId, sourceExtensionId, lineLength, isRandomSample) {\n                that._host.$reportTokenizationTime(timeMs, languageId, sourceExtensionId, lineLength, isRandomSample);\n            },\n        }, data.languageId, data.encodedLanguageId, data.maxTokenizationLineLength)));\n    }\n    $acceptModelChanged(controllerId, e) {\n        this._models.get(controllerId).onEvents(e);\n    }\n    $retokenize(controllerId, startLineNumber, endLineNumberExclusive) {\n        this._models.get(controllerId).retokenize(startLineNumber, endLineNumberExclusive);\n    }\n    $acceptModelLanguageChanged(controllerId, newLanguageId, newEncodedLanguageId) {\n        this._models.get(controllerId).onLanguageId(newLanguageId, newEncodedLanguageId);\n    }\n    $acceptRemovedModel(controllerId) {\n        const model = this._models.get(controllerId);\n        if (model) {\n            model.dispose();\n            this._models.delete(controllerId);\n        }\n    }\n    async $acceptTheme(theme, colorMap) {\n        const grammarFactory = await this._grammarFactory;\n        grammarFactory?.setTheme(theme, colorMap);\n    }\n    $acceptMaxTokenizationLineLength(controllerId, value) {\n        this._models.get(controllerId).acceptMaxTokenizationLineLength(value);\n    }\n}\n\nexport { TextMateTokenizationWorker, create };\n","import { RunOnceScheduler } from 'vscode/vscode/vs/base/common/async';\nimport { observableValue } from 'vscode/vscode/vs/base/common/observableInternal/base';\nimport 'vscode/vscode/vs/base/common/arrays';\nimport 'vscode/vscode/vs/base/common/event';\nimport { Disposable } from 'vscode/vscode/vs/base/common/lifecycle';\nimport 'vscode/vscode/vs/base/common/observableInternal/autorun';\nimport 'vscode/vscode/vs/base/common/observableInternal/derived';\nimport 'vscode/vscode/vs/base/common/cancellation';\nimport 'vscode/vscode/vs/base/common/observableInternal/utils';\nimport { setTimeout0 } from 'vscode/vscode/vs/base/common/platform';\nimport { LineRange } from 'vscode/vscode/vs/editor/common/core/lineRange';\nimport { MirrorTextModel } from 'vscode/vscode/vs/editor/common/model/mirrorTextModel';\nimport { TokenizerWithStateStore } from 'vscode/vscode/vs/editor/common/model/textModelTokens';\nimport { ContiguousMultilineTokensBuilder } from 'vscode/vscode/vs/editor/common/tokens/contiguousMultilineTokensBuilder';\nimport { LineTokens } from 'vscode/vscode/vs/editor/common/tokens/lineTokens';\nimport { TextMateTokenizationSupport } from '../../tokenizationSupport/textMateTokenizationSupport.js';\nimport { TokenizationSupportWithLineLimit } from '../../tokenizationSupport/tokenizationSupportWithLineLimit.js';\n\nclass TextMateWorkerTokenizer extends MirrorTextModel {\n    constructor(uri, lines, eol, versionId, _host, _languageId, _encodedLanguageId, maxTokenizationLineLength) {\n        super(uri, lines, eol, versionId);\n        this._host = _host;\n        this._languageId = _languageId;\n        this._encodedLanguageId = _encodedLanguageId;\n        this._tokenizerWithStateStore = null;\n        this._isDisposed = false;\n        this._maxTokenizationLineLength = observableValue(this, -1);\n        this._tokenizeDebouncer = ( new RunOnceScheduler(() => this._tokenize(), 10));\n        this._maxTokenizationLineLength.set(maxTokenizationLineLength, undefined);\n        this._resetTokenization();\n    }\n    dispose() {\n        this._isDisposed = true;\n        super.dispose();\n    }\n    onLanguageId(languageId, encodedLanguageId) {\n        this._languageId = languageId;\n        this._encodedLanguageId = encodedLanguageId;\n        this._resetTokenization();\n    }\n    onEvents(e) {\n        super.onEvents(e);\n        this._tokenizerWithStateStore?.store.acceptChanges(e.changes);\n        this._tokenizeDebouncer.schedule();\n    }\n    acceptMaxTokenizationLineLength(maxTokenizationLineLength) {\n        this._maxTokenizationLineLength.set(maxTokenizationLineLength, undefined);\n    }\n    retokenize(startLineNumber, endLineNumberExclusive) {\n        if (this._tokenizerWithStateStore) {\n            this._tokenizerWithStateStore.store.invalidateEndStateRange(( new LineRange(startLineNumber, endLineNumberExclusive)));\n            this._tokenizeDebouncer.schedule();\n        }\n    }\n    async _resetTokenization() {\n        this._tokenizerWithStateStore = null;\n        const languageId = this._languageId;\n        const encodedLanguageId = this._encodedLanguageId;\n        const r = await this._host.getOrCreateGrammar(languageId, encodedLanguageId);\n        if (this._isDisposed || languageId !== this._languageId || encodedLanguageId !== this._encodedLanguageId || !r) {\n            return;\n        }\n        if (r.grammar) {\n            const tokenizationSupport = ( new TokenizationSupportWithLineLimit(this._encodedLanguageId, ( new TextMateTokenizationSupport(\n                r.grammar,\n                r.initialState,\n                false,\n                undefined,\n                () => false,\n                (timeMs, lineLength, isRandomSample) => {\n                    this._host.reportTokenizationTime(timeMs, languageId, r.sourceExtensionId, lineLength, isRandomSample);\n                },\n                false\n            )), Disposable.None, this._maxTokenizationLineLength));\n            this._tokenizerWithStateStore = ( new TokenizerWithStateStore(this._lines.length, tokenizationSupport));\n        }\n        else {\n            this._tokenizerWithStateStore = null;\n        }\n        this._tokenize();\n    }\n    async _tokenize() {\n        if (this._isDisposed || !this._tokenizerWithStateStore) {\n            return;\n        }\n        if (!this._diffStateStacksRefEqFn) {\n            const { diffStateStacksRefEq } = await import('vscode-textmate').then(module => module.default ?? module);\n            this._diffStateStacksRefEqFn = diffStateStacksRefEq;\n        }\n        const startTime = ( new Date()).getTime();\n        while (true) {\n            let tokenizedLines = 0;\n            const tokenBuilder = ( new ContiguousMultilineTokensBuilder());\n            const stateDeltaBuilder = ( new StateDeltaBuilder());\n            while (true) {\n                const lineToTokenize = this._tokenizerWithStateStore.getFirstInvalidLine();\n                if (lineToTokenize === null || tokenizedLines > 200) {\n                    break;\n                }\n                tokenizedLines++;\n                const text = this._lines[lineToTokenize.lineNumber - 1];\n                const r = this._tokenizerWithStateStore.tokenizationSupport.tokenizeEncoded(text, true, lineToTokenize.startState);\n                if (this._tokenizerWithStateStore.store.setEndState(lineToTokenize.lineNumber, r.endState)) {\n                    const delta = this._diffStateStacksRefEqFn(lineToTokenize.startState, r.endState);\n                    stateDeltaBuilder.setState(lineToTokenize.lineNumber, delta);\n                }\n                else {\n                    stateDeltaBuilder.setState(lineToTokenize.lineNumber, null);\n                }\n                LineTokens.convertToEndOffset(r.tokens, text.length);\n                tokenBuilder.add(lineToTokenize.lineNumber, r.tokens);\n                const deltaMs = ( new Date()).getTime() - startTime;\n                if (deltaMs > 20) {\n                    break;\n                }\n            }\n            if (tokenizedLines === 0) {\n                break;\n            }\n            const stateDeltas = stateDeltaBuilder.getStateDeltas();\n            this._host.setTokensAndStates(this._versionId, tokenBuilder.serialize(), stateDeltas);\n            const deltaMs = ( new Date()).getTime() - startTime;\n            if (deltaMs > 20) {\n                setTimeout0(() => this._tokenize());\n                return;\n            }\n        }\n    }\n}\nclass StateDeltaBuilder {\n    constructor() {\n        this._lastStartLineNumber = -1;\n        this._stateDeltas = [];\n    }\n    setState(lineNumber, stackDiff) {\n        if (lineNumber === this._lastStartLineNumber + 1) {\n            this._stateDeltas[this._stateDeltas.length - 1].stateDeltas.push(stackDiff);\n        }\n        else {\n            this._stateDeltas.push({ startLineNumber: lineNumber, stateDeltas: [stackDiff] });\n        }\n        this._lastStartLineNumber = lineNumber;\n    }\n    getStateDeltas() {\n        return this._stateDeltas;\n    }\n}\n\nexport { TextMateWorkerTokenizer };\n","import './workers/textmate.worker.js';\n","import '../vscode/src/vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.worker.esm.js';\n","import { SimpleWorkerServer } from './simpleWorker.js';\nlet initialized = false;\nfunction initialize(factory) {\n    if (initialized) {\n        return;\n    }\n    initialized = true;\n    const simpleWorker = ( new SimpleWorkerServer(\n        msg => globalThis.postMessage(msg),\n        (workerServer) => factory(workerServer)\n    ));\n    globalThis.onmessage = (e) => {\n        simpleWorker.onmessage(e.data);\n    };\n}\nfunction bootstrapSimpleWorker(factory) {\n    globalThis.onmessage = (_e) => {\n        if (!initialized) {\n            initialize(factory);\n        }\n    };\n}\nexport { bootstrapSimpleWorker };\n","class TokenMetadata {\n    static getLanguageId(metadata) {\n        return ((metadata & 255) ) >>> 0 ;\n    }\n    static getTokenType(metadata) {\n        return ((metadata & 768) ) >>> 8 ;\n    }\n    static containsBalancedBrackets(metadata) {\n        return ((metadata & 1024) ) !== 0;\n    }\n    static getFontStyle(metadata) {\n        return ((metadata & 30720) ) >>> 11 ;\n    }\n    static getForeground(metadata) {\n        return ((metadata & 16744448) ) >>> 15 ;\n    }\n    static getBackground(metadata) {\n        return ((metadata & 4278190080) ) >>> 24 ;\n    }\n    static getClassNameFromMetadata(metadata) {\n        const foreground = this.getForeground(metadata);\n        let className = 'mtk' + foreground;\n        const fontStyle = this.getFontStyle(metadata);\n        if (fontStyle & 1 ) {\n            className += ' mtki';\n        }\n        if (fontStyle & 2 ) {\n            className += ' mtkb';\n        }\n        if (fontStyle & 4 ) {\n            className += ' mtku';\n        }\n        if (fontStyle & 8 ) {\n            className += ' mtks';\n        }\n        return className;\n    }\n    static getInlineStyleFromMetadata(metadata, colorMap) {\n        const foreground = this.getForeground(metadata);\n        const fontStyle = this.getFontStyle(metadata);\n        let result = `color: ${colorMap[foreground]};`;\n        if (fontStyle & 1 ) {\n            result += 'font-style: italic;';\n        }\n        if (fontStyle & 2 ) {\n            result += 'font-weight: bold;';\n        }\n        let textDecoration = '';\n        if (fontStyle & 4 ) {\n            textDecoration += ' underline';\n        }\n        if (fontStyle & 8 ) {\n            textDecoration += ' line-through';\n        }\n        if (textDecoration) {\n            result += `text-decoration:${textDecoration};`;\n        }\n        return result;\n    }\n    static getPresentationFromMetadata(metadata) {\n        const foreground = this.getForeground(metadata);\n        const fontStyle = this.getFontStyle(metadata);\n        return {\n            foreground: foreground,\n            italic: Boolean(fontStyle & 1 ),\n            bold: Boolean(fontStyle & 2 ),\n            underline: Boolean(fontStyle & 4 ),\n            strikethrough: Boolean(fontStyle & 8 ),\n        };\n    }\n}\nexport { TokenMetadata };\n","import { TokenizationResult, Token, EncodedTokenizationResult } from '../languages.js';\nconst NullState = new class {\n    clone() {\n        return this;\n    }\n    equals(other) {\n        return (this === other);\n    }\n};\nfunction nullTokenize(languageId, state) {\n    return ( new TokenizationResult([( new Token(0, '', languageId))], state));\n}\nfunction nullTokenizeEncoded(languageId, state) {\n    const tokens = ( new Uint32Array(2));\n    tokens[0] = 0;\n    tokens[1] = (((languageId << 0) )\n        | ((0  << 8) )\n        | ((0  << 11) )\n        | ((1  << 15) )\n        | ((2  << 24) )) >>> 0;\n    return ( new EncodedTokenizationResult(tokens, state === null ? NullState : state));\n}\nexport { NullState, nullTokenize, nullTokenizeEncoded };\n","import { arrayInsert } from '../../../base/common/arrays.js';\nclass FixedArray {\n    constructor(_default) {\n        this._default = _default;\n        this._store = [];\n    }\n    get(index) {\n        if (index < this._store.length) {\n            return this._store[index];\n        }\n        return this._default;\n    }\n    set(index, value) {\n        while (index >= this._store.length) {\n            this._store[this._store.length] = this._default;\n        }\n        this._store[index] = value;\n    }\n    replace(index, oldLength, newLength) {\n        if (index >= this._store.length) {\n            return;\n        }\n        if (oldLength === 0) {\n            this.insert(index, newLength);\n            return;\n        }\n        else if (newLength === 0) {\n            this.delete(index, oldLength);\n            return;\n        }\n        const before = this._store.slice(0, index);\n        const after = this._store.slice(index + oldLength);\n        const insertArr = arrayFill(newLength, this._default);\n        this._store = before.concat(insertArr, after);\n    }\n    delete(deleteIndex, deleteCount) {\n        if (deleteCount === 0 || deleteIndex >= this._store.length) {\n            return;\n        }\n        this._store.splice(deleteIndex, deleteCount);\n    }\n    insert(insertIndex, insertCount) {\n        if (insertCount === 0 || insertIndex >= this._store.length) {\n            return;\n        }\n        const arr = [];\n        for (let i = 0; i < insertCount; i++) {\n            arr[i] = this._default;\n        }\n        this._store = arrayInsert(this._store, insertIndex, arr);\n    }\n}\nfunction arrayFill(length, value) {\n    const arr = [];\n    for (let i = 0; i < length; i++) {\n        arr[i] = value;\n    }\n    return arr;\n}\nexport { FixedArray };\n","import { runWhenGlobalIdle } from '../../../base/common/async.js';\nimport { BugIndicatingError, onUnexpectedError } from '../../../base/common/errors.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { LineRange } from '../core/lineRange.js';\nimport { OffsetRange } from '../core/offsetRange.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { FixedArray } from './fixedArray.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nclass TokenizerWithStateStore {\n    constructor(lineCount, tokenizationSupport) {\n        this.tokenizationSupport = tokenizationSupport;\n        this.initialState = this.tokenizationSupport.getInitialState();\n        this.store = ( new TrackingTokenizationStateStore(lineCount));\n    }\n    getStartState(lineNumber) {\n        return this.store.getStartState(lineNumber, this.initialState);\n    }\n    getFirstInvalidLine() {\n        return this.store.getFirstInvalidLine(this.initialState);\n    }\n}\nclass TokenizerWithStateStoreAndTextModel extends TokenizerWithStateStore {\n    constructor(lineCount, tokenizationSupport, _textModel, _languageIdCodec) {\n        super(lineCount, tokenizationSupport);\n        this._textModel = _textModel;\n        this._languageIdCodec = _languageIdCodec;\n    }\n    updateTokensUntilLine(builder, lineNumber) {\n        const languageId = this._textModel.getLanguageId();\n        while (true) {\n            const lineToTokenize = this.getFirstInvalidLine();\n            if (!lineToTokenize || lineToTokenize.lineNumber > lineNumber) {\n                break;\n            }\n            const text = this._textModel.getLineContent(lineToTokenize.lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineToTokenize.startState);\n            builder.add(lineToTokenize.lineNumber, r.tokens);\n            this.store.setEndState(lineToTokenize.lineNumber, r.endState);\n        }\n    }\n    getTokenTypeIfInsertingCharacter(position, character) {\n        const lineStartState = this.getStartState(position.lineNumber);\n        if (!lineStartState) {\n            return 0 ;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const lineContent = this._textModel.getLineContent(position.lineNumber);\n        const text = (lineContent.substring(0, position.column - 1)\n            + character\n            + lineContent.substring(position.column - 1));\n        const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineStartState);\n        const lineTokens = ( new LineTokens(r.tokens, text, this._languageIdCodec));\n        if (lineTokens.getCount() === 0) {\n            return 0 ;\n        }\n        const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n        return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    tokenizeLineWithEdit(lineNumber, edit) {\n        const lineStartState = this.getStartState(lineNumber);\n        if (!lineStartState) {\n            return { mainLineTokens: null, additionalLines: null };\n        }\n        const curLineContent = this._textModel.getLineContent(lineNumber);\n        const newLineContent = edit.lineEdit.apply(curLineContent);\n        const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n        const result = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, newLineContent, true, lineStartState);\n        let additionalLines = null;\n        if (edit.additionalLines) {\n            additionalLines = [];\n            let state = result.endState;\n            for (const line of edit.additionalLines) {\n                const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, line, true, state);\n                additionalLines.push(( new LineTokens(r.tokens, line, this._languageIdCodec)));\n                state = r.endState;\n            }\n        }\n        const mainLineTokens = ( new LineTokens(result.tokens, newLineContent, this._languageIdCodec));\n        return { mainLineTokens, additionalLines };\n    }\n    hasAccurateTokensForLine(lineNumber) {\n        const firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n        return (lineNumber < firstInvalidLineNumber);\n    }\n    isCheapToTokenize(lineNumber) {\n        const firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n        if (lineNumber < firstInvalidLineNumber) {\n            return true;\n        }\n        if (lineNumber === firstInvalidLineNumber\n            && this._textModel.getLineLength(lineNumber) < 2048 ) {\n            return true;\n        }\n        return false;\n    }\n    tokenizeHeuristically(builder, startLineNumber, endLineNumber) {\n        if (endLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n            return { heuristicTokens: false };\n        }\n        if (startLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n            this.updateTokensUntilLine(builder, endLineNumber);\n            return { heuristicTokens: false };\n        }\n        let state = this.guessStartState(startLineNumber);\n        const languageId = this._textModel.getLanguageId();\n        for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n            const text = this._textModel.getLineContent(lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, state);\n            builder.add(lineNumber, r.tokens);\n            state = r.endState;\n        }\n        return { heuristicTokens: true };\n    }\n    guessStartState(lineNumber) {\n        let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(lineNumber);\n        const likelyRelevantLines = [];\n        let initialState = null;\n        for (let i = lineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n            const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n            if (newNonWhitespaceIndex === 0) {\n                continue;\n            }\n            if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n                likelyRelevantLines.push(this._textModel.getLineContent(i));\n                nonWhitespaceColumn = newNonWhitespaceIndex;\n                initialState = this.getStartState(i);\n                if (initialState) {\n                    break;\n                }\n            }\n        }\n        if (!initialState) {\n            initialState = this.tokenizationSupport.getInitialState();\n        }\n        likelyRelevantLines.reverse();\n        const languageId = this._textModel.getLanguageId();\n        let state = initialState;\n        for (const line of likelyRelevantLines) {\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, line, false, state);\n            state = r.endState;\n        }\n        return state;\n    }\n}\nclass TrackingTokenizationStateStore {\n    constructor(lineCount) {\n        this.lineCount = lineCount;\n        this._tokenizationStateStore = ( new TokenizationStateStore());\n        this._invalidEndStatesLineNumbers = ( new RangePriorityQueueImpl());\n        this._invalidEndStatesLineNumbers.addRange(( new OffsetRange(1, lineCount + 1)));\n    }\n    getEndState(lineNumber) {\n        return this._tokenizationStateStore.getEndState(lineNumber);\n    }\n    setEndState(lineNumber, state) {\n        if (!state) {\n            throw ( new BugIndicatingError('Cannot set null/undefined state'));\n        }\n        this._invalidEndStatesLineNumbers.delete(lineNumber);\n        const r = this._tokenizationStateStore.setEndState(lineNumber, state);\n        if (r && lineNumber < this.lineCount) {\n            this._invalidEndStatesLineNumbers.addRange(( new OffsetRange(lineNumber + 1, lineNumber + 2)));\n        }\n        return r;\n    }\n    acceptChange(range, newLineCount) {\n        this.lineCount += newLineCount - range.length;\n        this._tokenizationStateStore.acceptChange(range, newLineCount);\n        this._invalidEndStatesLineNumbers.addRangeAndResize(( new OffsetRange(range.startLineNumber, range.endLineNumberExclusive)), newLineCount);\n    }\n    acceptChanges(changes) {\n        for (const c of changes) {\n            const [eolCount] = countEOL(c.text);\n            this.acceptChange(( new LineRange(c.range.startLineNumber, c.range.endLineNumber + 1)), eolCount + 1);\n        }\n    }\n    invalidateEndStateRange(range) {\n        this._invalidEndStatesLineNumbers.addRange(( new OffsetRange(range.startLineNumber, range.endLineNumberExclusive)));\n    }\n    getFirstInvalidEndStateLineNumber() { return this._invalidEndStatesLineNumbers.min; }\n    getFirstInvalidEndStateLineNumberOrMax() {\n        return this.getFirstInvalidEndStateLineNumber() || Number.MAX_SAFE_INTEGER;\n    }\n    allStatesValid() { return this._invalidEndStatesLineNumbers.min === null; }\n    getStartState(lineNumber, initialState) {\n        if (lineNumber === 1) {\n            return initialState;\n        }\n        return this.getEndState(lineNumber - 1);\n    }\n    getFirstInvalidLine(initialState) {\n        const lineNumber = this.getFirstInvalidEndStateLineNumber();\n        if (lineNumber === null) {\n            return null;\n        }\n        const startState = this.getStartState(lineNumber, initialState);\n        if (!startState) {\n            throw ( new BugIndicatingError('Start state must be defined'));\n        }\n        return { lineNumber, startState };\n    }\n}\nclass TokenizationStateStore {\n    constructor() {\n        this._lineEndStates = ( new FixedArray(null));\n    }\n    getEndState(lineNumber) {\n        return this._lineEndStates.get(lineNumber);\n    }\n    setEndState(lineNumber, state) {\n        const oldState = this._lineEndStates.get(lineNumber);\n        if (oldState && oldState.equals(state)) {\n            return false;\n        }\n        this._lineEndStates.set(lineNumber, state);\n        return true;\n    }\n    acceptChange(range, newLineCount) {\n        let length = range.length;\n        if (newLineCount > 0 && length > 0) {\n            length--;\n            newLineCount--;\n        }\n        this._lineEndStates.replace(range.startLineNumber, length, newLineCount);\n    }\n    acceptChanges(changes) {\n        for (const c of changes) {\n            const [eolCount] = countEOL(c.text);\n            this.acceptChange(( new LineRange(c.range.startLineNumber, c.range.endLineNumber + 1)), eolCount + 1);\n        }\n    }\n}\nclass RangePriorityQueueImpl {\n    constructor() {\n        this._ranges = [];\n    }\n    getRanges() {\n        return this._ranges;\n    }\n    get min() {\n        if (this._ranges.length === 0) {\n            return null;\n        }\n        return this._ranges[0].start;\n    }\n    removeMin() {\n        if (this._ranges.length === 0) {\n            return null;\n        }\n        const range = this._ranges[0];\n        if (range.start + 1 === range.endExclusive) {\n            this._ranges.shift();\n        }\n        else {\n            this._ranges[0] = ( new OffsetRange(range.start + 1, range.endExclusive));\n        }\n        return range.start;\n    }\n    delete(value) {\n        const idx = this._ranges.findIndex(r => r.contains(value));\n        if (idx !== -1) {\n            const range = this._ranges[idx];\n            if (range.start === value) {\n                if (range.endExclusive === value + 1) {\n                    this._ranges.splice(idx, 1);\n                }\n                else {\n                    this._ranges[idx] = ( new OffsetRange(value + 1, range.endExclusive));\n                }\n            }\n            else {\n                if (range.endExclusive === value + 1) {\n                    this._ranges[idx] = ( new OffsetRange(range.start, value));\n                }\n                else {\n                    this._ranges.splice(idx, 1, ( new OffsetRange(range.start, value)), ( new OffsetRange(value + 1, range.endExclusive)));\n                }\n            }\n        }\n    }\n    addRange(range) {\n        OffsetRange.addRange(range, this._ranges);\n    }\n    addRangeAndResize(range, newLength) {\n        let idxFirstMightBeIntersecting = 0;\n        while (!(idxFirstMightBeIntersecting >= this._ranges.length || range.start <= this._ranges[idxFirstMightBeIntersecting].endExclusive)) {\n            idxFirstMightBeIntersecting++;\n        }\n        let idxFirstIsAfter = idxFirstMightBeIntersecting;\n        while (!(idxFirstIsAfter >= this._ranges.length || range.endExclusive < this._ranges[idxFirstIsAfter].start)) {\n            idxFirstIsAfter++;\n        }\n        const delta = newLength - range.length;\n        for (let i = idxFirstIsAfter; i < this._ranges.length; i++) {\n            this._ranges[i] = this._ranges[i].delta(delta);\n        }\n        if (idxFirstMightBeIntersecting === idxFirstIsAfter) {\n            const newRange = ( new OffsetRange(range.start, range.start + newLength));\n            if (!newRange.isEmpty) {\n                this._ranges.splice(idxFirstMightBeIntersecting, 0, newRange);\n            }\n        }\n        else {\n            const start = Math.min(range.start, this._ranges[idxFirstMightBeIntersecting].start);\n            const endEx = Math.max(range.endExclusive, this._ranges[idxFirstIsAfter - 1].endExclusive);\n            const newRange = ( new OffsetRange(start, endEx + delta));\n            if (!newRange.isEmpty) {\n                this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting, newRange);\n            }\n            else {\n                this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting);\n            }\n        }\n    }\n    toString() {\n        return ( this._ranges.map(r => ( r.toString()))).join(' + ');\n    }\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n    let r = null;\n    if (tokenizationSupport) {\n        try {\n            r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n        }\n        catch (e) {\n            onUnexpectedError(e);\n        }\n    }\n    if (!r) {\n        r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n    }\n    LineTokens.convertToEndOffset(r.tokens, text.length);\n    return r;\n}\nclass DefaultBackgroundTokenizer {\n    constructor(_tokenizerWithStateStore, _backgroundTokenStore) {\n        this._tokenizerWithStateStore = _tokenizerWithStateStore;\n        this._backgroundTokenStore = _backgroundTokenStore;\n        this._isDisposed = false;\n        this._isScheduled = false;\n    }\n    dispose() {\n        this._isDisposed = true;\n    }\n    handleChanges() {\n        this._beginBackgroundTokenization();\n    }\n    _beginBackgroundTokenization() {\n        if (this._isScheduled || !this._tokenizerWithStateStore._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n            return;\n        }\n        this._isScheduled = true;\n        runWhenGlobalIdle((deadline) => {\n            this._isScheduled = false;\n            this._backgroundTokenizeWithDeadline(deadline);\n        });\n    }\n    _backgroundTokenizeWithDeadline(deadline) {\n        const endTime = Date.now() + deadline.timeRemaining();\n        const execute = () => {\n            if (this._isDisposed || !this._tokenizerWithStateStore._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n                return;\n            }\n            this._backgroundTokenizeForAtLeast1ms();\n            if (Date.now() < endTime) {\n                setTimeout0(execute);\n            }\n            else {\n                this._beginBackgroundTokenization();\n            }\n        };\n        execute();\n    }\n    _backgroundTokenizeForAtLeast1ms() {\n        const lineCount = this._tokenizerWithStateStore._textModel.getLineCount();\n        const builder = ( new ContiguousMultilineTokensBuilder());\n        const sw = StopWatch.create(false);\n        do {\n            if (sw.elapsed() > 1) {\n                break;\n            }\n            const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n            if (tokenizedLineNumber >= lineCount) {\n                break;\n            }\n        } while (this._hasLinesToTokenize());\n        this._backgroundTokenStore.setTokens(builder.finalize());\n        this.checkFinished();\n    }\n    _hasLinesToTokenize() {\n        if (!this._tokenizerWithStateStore) {\n            return false;\n        }\n        return !this._tokenizerWithStateStore.store.allStatesValid();\n    }\n    _tokenizeOneInvalidLine(builder) {\n        const firstInvalidLine = this._tokenizerWithStateStore?.getFirstInvalidLine();\n        if (!firstInvalidLine) {\n            return this._tokenizerWithStateStore._textModel.getLineCount() + 1;\n        }\n        this._tokenizerWithStateStore.updateTokensUntilLine(builder, firstInvalidLine.lineNumber);\n        return firstInvalidLine.lineNumber;\n    }\n    checkFinished() {\n        if (this._isDisposed) {\n            return;\n        }\n        if (this._tokenizerWithStateStore.store.allStatesValid()) {\n            this._backgroundTokenStore.backgroundTokenizationFinished();\n        }\n    }\n    requestTokens(startLineNumber, endLineNumberExclusive) {\n        this._tokenizerWithStateStore.store.invalidateEndStateRange(( new LineRange(startLineNumber, endLineNumberExclusive)));\n    }\n}\nexport { DefaultBackgroundTokenizer, RangePriorityQueueImpl, TokenizationStateStore, TokenizerWithStateStore, TokenizerWithStateStoreAndTextModel, TrackingTokenizationStateStore };\n","import { arrayInsert } from '../../../base/common/arrays.js';\nimport { writeUInt32BE, readUInt32BE } from '../../../base/common/buffer.js';\nimport { Position } from '../core/position.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { ContiguousTokensEditing } from './contiguousTokensEditing.js';\nimport { LineRange } from '../core/lineRange.js';\nclass ContiguousMultilineTokens {\n    static deserialize(buff, offset, result) {\n        const view32 = ( new Uint32Array(buff.buffer));\n        const startLineNumber = readUInt32BE(buff, offset);\n        offset += 4;\n        const count = readUInt32BE(buff, offset);\n        offset += 4;\n        const tokens = [];\n        for (let i = 0; i < count; i++) {\n            const byteCount = readUInt32BE(buff, offset);\n            offset += 4;\n            tokens.push(view32.subarray(offset / 4, offset / 4 + byteCount / 4));\n            offset += byteCount;\n        }\n        result.push(( new ContiguousMultilineTokens(startLineNumber, tokens)));\n        return offset;\n    }\n    get startLineNumber() {\n        return this._startLineNumber;\n    }\n    get endLineNumber() {\n        return this._startLineNumber + this._tokens.length - 1;\n    }\n    constructor(startLineNumber, tokens) {\n        this._startLineNumber = startLineNumber;\n        this._tokens = tokens;\n    }\n    getLineRange() {\n        return ( new LineRange(this._startLineNumber, this._startLineNumber + this._tokens.length));\n    }\n    getLineTokens(lineNumber) {\n        return this._tokens[lineNumber - this._startLineNumber];\n    }\n    appendLineTokens(lineTokens) {\n        this._tokens.push(lineTokens);\n    }\n    serializeSize() {\n        let result = 0;\n        result += 4;\n        result += 4;\n        for (let i = 0; i < this._tokens.length; i++) {\n            const lineTokens = this._tokens[i];\n            if (!(lineTokens instanceof Uint32Array)) {\n                throw ( new Error(`Not supported!`));\n            }\n            result += 4;\n            result += lineTokens.byteLength;\n        }\n        return result;\n    }\n    serialize(destination, offset) {\n        writeUInt32BE(destination, this._startLineNumber, offset);\n        offset += 4;\n        writeUInt32BE(destination, this._tokens.length, offset);\n        offset += 4;\n        for (let i = 0; i < this._tokens.length; i++) {\n            const lineTokens = this._tokens[i];\n            if (!(lineTokens instanceof Uint32Array)) {\n                throw ( new Error(`Not supported!`));\n            }\n            writeUInt32BE(destination, lineTokens.byteLength, offset);\n            offset += 4;\n            destination.set(( new Uint8Array(lineTokens.buffer)), offset);\n            offset += lineTokens.byteLength;\n        }\n        return offset;\n    }\n    applyEdit(range, text) {\n        const [eolCount, firstLineLength] = countEOL(text);\n        this._acceptDeleteRange(range);\n        this._acceptInsertText(( new Position(range.startLineNumber, range.startColumn)), eolCount, firstLineLength);\n    }\n    _acceptDeleteRange(range) {\n        if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n            return;\n        }\n        const firstLineIndex = range.startLineNumber - this._startLineNumber;\n        const lastLineIndex = range.endLineNumber - this._startLineNumber;\n        if (lastLineIndex < 0) {\n            const deletedLinesCount = lastLineIndex - firstLineIndex;\n            this._startLineNumber -= deletedLinesCount;\n            return;\n        }\n        if (firstLineIndex >= this._tokens.length) {\n            return;\n        }\n        if (firstLineIndex < 0 && lastLineIndex >= this._tokens.length) {\n            this._startLineNumber = 0;\n            this._tokens = [];\n            return;\n        }\n        if (firstLineIndex === lastLineIndex) {\n            this._tokens[firstLineIndex] = ContiguousTokensEditing.delete(this._tokens[firstLineIndex], range.startColumn - 1, range.endColumn - 1);\n            return;\n        }\n        if (firstLineIndex >= 0) {\n            this._tokens[firstLineIndex] = ContiguousTokensEditing.deleteEnding(this._tokens[firstLineIndex], range.startColumn - 1);\n            if (lastLineIndex < this._tokens.length) {\n                const lastLineTokens = ContiguousTokensEditing.deleteBeginning(this._tokens[lastLineIndex], range.endColumn - 1);\n                this._tokens[firstLineIndex] = ContiguousTokensEditing.append(this._tokens[firstLineIndex], lastLineTokens);\n                this._tokens.splice(firstLineIndex + 1, lastLineIndex - firstLineIndex);\n            }\n            else {\n                this._tokens[firstLineIndex] = ContiguousTokensEditing.append(this._tokens[firstLineIndex], null);\n                this._tokens = this._tokens.slice(0, firstLineIndex + 1);\n            }\n        }\n        else {\n            const deletedBefore = -firstLineIndex;\n            this._startLineNumber -= deletedBefore;\n            this._tokens[lastLineIndex] = ContiguousTokensEditing.deleteBeginning(this._tokens[lastLineIndex], range.endColumn - 1);\n            this._tokens = this._tokens.slice(lastLineIndex);\n        }\n    }\n    _acceptInsertText(position, eolCount, firstLineLength) {\n        if (eolCount === 0 && firstLineLength === 0) {\n            return;\n        }\n        const lineIndex = position.lineNumber - this._startLineNumber;\n        if (lineIndex < 0) {\n            this._startLineNumber += eolCount;\n            return;\n        }\n        if (lineIndex >= this._tokens.length) {\n            return;\n        }\n        if (eolCount === 0) {\n            this._tokens[lineIndex] = ContiguousTokensEditing.insert(this._tokens[lineIndex], position.column - 1, firstLineLength);\n            return;\n        }\n        this._tokens[lineIndex] = ContiguousTokensEditing.deleteEnding(this._tokens[lineIndex], position.column - 1);\n        this._tokens[lineIndex] = ContiguousTokensEditing.insert(this._tokens[lineIndex], position.column - 1, firstLineLength);\n        this._insertLines(position.lineNumber, eolCount);\n    }\n    _insertLines(insertIndex, insertCount) {\n        if (insertCount === 0) {\n            return;\n        }\n        const lineTokens = [];\n        for (let i = 0; i < insertCount; i++) {\n            lineTokens[i] = null;\n        }\n        this._tokens = arrayInsert(this._tokens, insertIndex, lineTokens);\n    }\n}\nexport { ContiguousMultilineTokens };\n","import { writeUInt32BE, readUInt32BE } from '../../../base/common/buffer.js';\nimport { ContiguousMultilineTokens } from './contiguousMultilineTokens.js';\nclass ContiguousMultilineTokensBuilder {\n    static deserialize(buff) {\n        let offset = 0;\n        const count = readUInt32BE(buff, offset);\n        offset += 4;\n        const result = [];\n        for (let i = 0; i < count; i++) {\n            offset = ContiguousMultilineTokens.deserialize(buff, offset, result);\n        }\n        return result;\n    }\n    constructor() {\n        this._tokens = [];\n    }\n    add(lineNumber, lineTokens) {\n        if (this._tokens.length > 0) {\n            const last = this._tokens[this._tokens.length - 1];\n            if (last.endLineNumber + 1 === lineNumber) {\n                last.appendLineTokens(lineTokens);\n                return;\n            }\n        }\n        this._tokens.push(( new ContiguousMultilineTokens(lineNumber, [lineTokens])));\n    }\n    finalize() {\n        return this._tokens;\n    }\n    serialize() {\n        const size = this._serializeSize();\n        const result = ( new Uint8Array(size));\n        this._serialize(result);\n        return result;\n    }\n    _serializeSize() {\n        let result = 0;\n        result += 4;\n        for (let i = 0; i < this._tokens.length; i++) {\n            result += this._tokens[i].serializeSize();\n        }\n        return result;\n    }\n    _serialize(destination) {\n        let offset = 0;\n        writeUInt32BE(destination, this._tokens.length, offset);\n        offset += 4;\n        for (let i = 0; i < this._tokens.length; i++) {\n            offset = this._tokens[i].serialize(destination, offset);\n        }\n    }\n}\nexport { ContiguousMultilineTokensBuilder };\n","import { LineTokens } from './lineTokens.js';\nconst EMPTY_LINE_TOKENS = (( new Uint32Array(0))).buffer;\nclass ContiguousTokensEditing {\n    static deleteBeginning(lineTokens, toChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        return ContiguousTokensEditing.delete(lineTokens, 0, toChIndex);\n    }\n    static deleteEnding(lineTokens, fromChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const lineTextLength = tokens[tokens.length - 2];\n        return ContiguousTokensEditing.delete(lineTokens, fromChIndex, lineTextLength);\n    }\n    static delete(lineTokens, fromChIndex, toChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS || fromChIndex === toChIndex) {\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const tokensCount = (tokens.length >>> 1);\n        if (fromChIndex === 0 && tokens[tokens.length - 2] === toChIndex) {\n            return EMPTY_LINE_TOKENS;\n        }\n        const fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, fromChIndex);\n        const fromTokenStartOffset = (fromTokenIndex > 0 ? tokens[(fromTokenIndex - 1) << 1] : 0);\n        const fromTokenEndOffset = tokens[fromTokenIndex << 1];\n        if (toChIndex < fromTokenEndOffset) {\n            const delta = (toChIndex - fromChIndex);\n            for (let i = fromTokenIndex; i < tokensCount; i++) {\n                tokens[i << 1] -= delta;\n            }\n            return lineTokens;\n        }\n        let dest;\n        let lastEnd;\n        if (fromTokenStartOffset !== fromChIndex) {\n            tokens[fromTokenIndex << 1] = fromChIndex;\n            dest = ((fromTokenIndex + 1) << 1);\n            lastEnd = fromChIndex;\n        }\n        else {\n            dest = (fromTokenIndex << 1);\n            lastEnd = fromTokenStartOffset;\n        }\n        const delta = (toChIndex - fromChIndex);\n        for (let tokenIndex = fromTokenIndex + 1; tokenIndex < tokensCount; tokenIndex++) {\n            const tokenEndOffset = tokens[tokenIndex << 1] - delta;\n            if (tokenEndOffset > lastEnd) {\n                tokens[dest++] = tokenEndOffset;\n                tokens[dest++] = tokens[(tokenIndex << 1) + 1];\n                lastEnd = tokenEndOffset;\n            }\n        }\n        if (dest === tokens.length) {\n            return lineTokens;\n        }\n        const tmp = ( new Uint32Array(dest));\n        tmp.set(tokens.subarray(0, dest), 0);\n        return tmp.buffer;\n    }\n    static append(lineTokens, _otherTokens) {\n        if (_otherTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        if (lineTokens === EMPTY_LINE_TOKENS) {\n            return _otherTokens;\n        }\n        if (lineTokens === null) {\n            return lineTokens;\n        }\n        if (_otherTokens === null) {\n            return null;\n        }\n        const myTokens = toUint32Array(lineTokens);\n        const otherTokens = toUint32Array(_otherTokens);\n        const otherTokensCount = (otherTokens.length >>> 1);\n        const result = ( new Uint32Array(myTokens.length + otherTokens.length));\n        result.set(myTokens, 0);\n        let dest = myTokens.length;\n        const delta = myTokens[myTokens.length - 2];\n        for (let i = 0; i < otherTokensCount; i++) {\n            result[dest++] = otherTokens[(i << 1)] + delta;\n            result[dest++] = otherTokens[(i << 1) + 1];\n        }\n        return result.buffer;\n    }\n    static insert(lineTokens, chIndex, textLength) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const tokensCount = (tokens.length >>> 1);\n        let fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, chIndex);\n        if (fromTokenIndex > 0) {\n            const fromTokenStartOffset = tokens[(fromTokenIndex - 1) << 1];\n            if (fromTokenStartOffset === chIndex) {\n                fromTokenIndex--;\n            }\n        }\n        for (let tokenIndex = fromTokenIndex; tokenIndex < tokensCount; tokenIndex++) {\n            tokens[tokenIndex << 1] += textLength;\n        }\n        return lineTokens;\n    }\n}\nfunction toUint32Array(arr) {\n    if (arr instanceof Uint32Array) {\n        return arr;\n    }\n    else {\n        return ( new Uint32Array(arr));\n    }\n}\nexport { ContiguousTokensEditing, EMPTY_LINE_TOKENS, toUint32Array };\n","import { TokenMetadata } from '../encodedTokenAttributes.js';\nimport { OffsetRange } from '../core/offsetRange.js';\nimport { TokenArrayBuilder } from './tokenArray.js';\nclass LineTokens {\n    static createEmpty(lineContent, decoder) {\n        const defaultMetadata = LineTokens.defaultTokenMetadata;\n        const tokens = ( new Uint32Array(2));\n        tokens[0] = lineContent.length;\n        tokens[1] = defaultMetadata;\n        return ( new LineTokens(tokens, lineContent, decoder));\n    }\n    static createFromTextAndMetadata(data, decoder) {\n        let offset = 0;\n        let fullText = '';\n        const tokens = ( new Array());\n        for (const { text, metadata } of data) {\n            tokens.push(offset + text.length, metadata);\n            offset += text.length;\n            fullText += text;\n        }\n        return ( new LineTokens(( new Uint32Array(tokens)), fullText, decoder));\n    }\n    static convertToEndOffset(tokens, lineTextLength) {\n        const tokenCount = (tokens.length >>> 1);\n        const lastTokenIndex = tokenCount - 1;\n        for (let tokenIndex = 0; tokenIndex < lastTokenIndex; tokenIndex++) {\n            tokens[tokenIndex << 1] = tokens[(tokenIndex + 1) << 1];\n        }\n        tokens[lastTokenIndex << 1] = lineTextLength;\n    }\n    static findIndexInTokensArray(tokens, desiredIndex) {\n        if (tokens.length <= 2) {\n            return 0;\n        }\n        let low = 0;\n        let high = (tokens.length >>> 1) - 1;\n        while (low < high) {\n            const mid = low + Math.floor((high - low) / 2);\n            const endOffset = tokens[(mid << 1)];\n            if (endOffset === desiredIndex) {\n                return mid + 1;\n            }\n            else if (endOffset < desiredIndex) {\n                low = mid + 1;\n            }\n            else if (endOffset > desiredIndex) {\n                high = mid;\n            }\n        }\n        return low;\n    }\n    static { this.defaultTokenMetadata = (((0  << 11) )\n        | ((1  << 15) )\n        | ((2  << 24) )) >>> 0; }\n    constructor(tokens, text, decoder) {\n        this._lineTokensBrand = undefined;\n        this._tokens = tokens;\n        this._tokensCount = (this._tokens.length >>> 1);\n        this._text = text;\n        this.languageIdCodec = decoder;\n    }\n    equals(other) {\n        if (other instanceof LineTokens) {\n            return this.slicedEquals(other, 0, this._tokensCount);\n        }\n        return false;\n    }\n    slicedEquals(other, sliceFromTokenIndex, sliceTokenCount) {\n        if (this._text !== other._text) {\n            return false;\n        }\n        if (this._tokensCount !== other._tokensCount) {\n            return false;\n        }\n        const from = (sliceFromTokenIndex << 1);\n        const to = from + (sliceTokenCount << 1);\n        for (let i = from; i < to; i++) {\n            if (this._tokens[i] !== other._tokens[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    getLineContent() {\n        return this._text;\n    }\n    getCount() {\n        return this._tokensCount;\n    }\n    getStartOffset(tokenIndex) {\n        if (tokenIndex > 0) {\n            return this._tokens[(tokenIndex - 1) << 1];\n        }\n        return 0;\n    }\n    getMetadata(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return metadata;\n    }\n    getLanguageId(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        const languageId = TokenMetadata.getLanguageId(metadata);\n        return this.languageIdCodec.decodeLanguageId(languageId);\n    }\n    getStandardTokenType(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return TokenMetadata.getTokenType(metadata);\n    }\n    getForeground(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return TokenMetadata.getForeground(metadata);\n    }\n    getClassName(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return TokenMetadata.getClassNameFromMetadata(metadata);\n    }\n    getInlineStyle(tokenIndex, colorMap) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return TokenMetadata.getInlineStyleFromMetadata(metadata, colorMap);\n    }\n    getPresentation(tokenIndex) {\n        const metadata = this._tokens[(tokenIndex << 1) + 1];\n        return TokenMetadata.getPresentationFromMetadata(metadata);\n    }\n    getEndOffset(tokenIndex) {\n        return this._tokens[tokenIndex << 1];\n    }\n    findTokenIndexAtOffset(offset) {\n        return LineTokens.findIndexInTokensArray(this._tokens, offset);\n    }\n    inflate() {\n        return this;\n    }\n    sliceAndInflate(startOffset, endOffset, deltaOffset) {\n        return ( new SliceLineTokens(this, startOffset, endOffset, deltaOffset));\n    }\n    withInserted(insertTokens) {\n        if (insertTokens.length === 0) {\n            return this;\n        }\n        let nextOriginalTokenIdx = 0;\n        let nextInsertTokenIdx = 0;\n        let text = '';\n        const newTokens = ( new Array());\n        let originalEndOffset = 0;\n        while (true) {\n            const nextOriginalTokenEndOffset = nextOriginalTokenIdx < this._tokensCount ? this._tokens[nextOriginalTokenIdx << 1] : -1;\n            const nextInsertToken = nextInsertTokenIdx < insertTokens.length ? insertTokens[nextInsertTokenIdx] : null;\n            if (nextOriginalTokenEndOffset !== -1 && (nextInsertToken === null || nextOriginalTokenEndOffset <= nextInsertToken.offset)) {\n                text += this._text.substring(originalEndOffset, nextOriginalTokenEndOffset);\n                const metadata = this._tokens[(nextOriginalTokenIdx << 1) + 1];\n                newTokens.push(text.length, metadata);\n                nextOriginalTokenIdx++;\n                originalEndOffset = nextOriginalTokenEndOffset;\n            }\n            else if (nextInsertToken) {\n                if (nextInsertToken.offset > originalEndOffset) {\n                    text += this._text.substring(originalEndOffset, nextInsertToken.offset);\n                    const metadata = this._tokens[(nextOriginalTokenIdx << 1) + 1];\n                    newTokens.push(text.length, metadata);\n                    originalEndOffset = nextInsertToken.offset;\n                }\n                text += nextInsertToken.text;\n                newTokens.push(text.length, nextInsertToken.tokenMetadata);\n                nextInsertTokenIdx++;\n            }\n            else {\n                break;\n            }\n        }\n        return ( new LineTokens(( new Uint32Array(newTokens)), text, this.languageIdCodec));\n    }\n    getTokensInRange(range) {\n        const builder = ( new TokenArrayBuilder());\n        const startTokenIndex = this.findTokenIndexAtOffset(range.start);\n        const endTokenIndex = this.findTokenIndexAtOffset(range.endExclusive);\n        for (let tokenIndex = startTokenIndex; tokenIndex <= endTokenIndex; tokenIndex++) {\n            const tokenRange = ( new OffsetRange(this.getStartOffset(tokenIndex), this.getEndOffset(tokenIndex)));\n            const length = tokenRange.intersectionLength(range);\n            if (length > 0) {\n                builder.add(length, this.getMetadata(tokenIndex));\n            }\n        }\n        return builder.build();\n    }\n    getTokenText(tokenIndex) {\n        const startOffset = this.getStartOffset(tokenIndex);\n        const endOffset = this.getEndOffset(tokenIndex);\n        const text = this._text.substring(startOffset, endOffset);\n        return text;\n    }\n    forEach(callback) {\n        const tokenCount = this.getCount();\n        for (let tokenIndex = 0; tokenIndex < tokenCount; tokenIndex++) {\n            callback(tokenIndex);\n        }\n    }\n}\nclass SliceLineTokens {\n    constructor(source, startOffset, endOffset, deltaOffset) {\n        this._source = source;\n        this._startOffset = startOffset;\n        this._endOffset = endOffset;\n        this._deltaOffset = deltaOffset;\n        this._firstTokenIndex = source.findTokenIndexAtOffset(startOffset);\n        this.languageIdCodec = source.languageIdCodec;\n        this._tokensCount = 0;\n        for (let i = this._firstTokenIndex, len = source.getCount(); i < len; i++) {\n            const tokenStartOffset = source.getStartOffset(i);\n            if (tokenStartOffset >= endOffset) {\n                break;\n            }\n            this._tokensCount++;\n        }\n    }\n    getMetadata(tokenIndex) {\n        return this._source.getMetadata(this._firstTokenIndex + tokenIndex);\n    }\n    getLanguageId(tokenIndex) {\n        return this._source.getLanguageId(this._firstTokenIndex + tokenIndex);\n    }\n    getLineContent() {\n        return this._source.getLineContent().substring(this._startOffset, this._endOffset);\n    }\n    equals(other) {\n        if (other instanceof SliceLineTokens) {\n            return (this._startOffset === other._startOffset\n                && this._endOffset === other._endOffset\n                && this._deltaOffset === other._deltaOffset\n                && this._source.slicedEquals(other._source, this._firstTokenIndex, this._tokensCount));\n        }\n        return false;\n    }\n    getCount() {\n        return this._tokensCount;\n    }\n    getStandardTokenType(tokenIndex) {\n        return this._source.getStandardTokenType(this._firstTokenIndex + tokenIndex);\n    }\n    getForeground(tokenIndex) {\n        return this._source.getForeground(this._firstTokenIndex + tokenIndex);\n    }\n    getEndOffset(tokenIndex) {\n        const tokenEndOffset = this._source.getEndOffset(this._firstTokenIndex + tokenIndex);\n        return Math.min(this._endOffset, tokenEndOffset) - this._startOffset + this._deltaOffset;\n    }\n    getClassName(tokenIndex) {\n        return this._source.getClassName(this._firstTokenIndex + tokenIndex);\n    }\n    getInlineStyle(tokenIndex, colorMap) {\n        return this._source.getInlineStyle(this._firstTokenIndex + tokenIndex, colorMap);\n    }\n    getPresentation(tokenIndex) {\n        return this._source.getPresentation(this._firstTokenIndex + tokenIndex);\n    }\n    findTokenIndexAtOffset(offset) {\n        return this._source.findTokenIndexAtOffset(offset + this._startOffset - this._deltaOffset) - this._firstTokenIndex;\n    }\n    getTokenText(tokenIndex) {\n        const adjustedTokenIndex = this._firstTokenIndex + tokenIndex;\n        const tokenStartOffset = this._source.getStartOffset(adjustedTokenIndex);\n        const tokenEndOffset = this._source.getEndOffset(adjustedTokenIndex);\n        let text = this._source.getTokenText(adjustedTokenIndex);\n        if (tokenStartOffset < this._startOffset) {\n            text = text.substring(this._startOffset - tokenStartOffset);\n        }\n        if (tokenEndOffset > this._endOffset) {\n            text = text.substring(0, text.length - (tokenEndOffset - this._endOffset));\n        }\n        return text;\n    }\n    forEach(callback) {\n        for (let tokenIndex = 0; tokenIndex < this.getCount(); tokenIndex++) {\n            callback(tokenIndex);\n        }\n    }\n}\nfunction getStandardTokenTypeAtPosition(model, position) {\n    const lineNumber = position.lineNumber;\n    if (!model.tokenization.isCheapToTokenize(lineNumber)) {\n        return undefined;\n    }\n    model.tokenization.forceTokenization(lineNumber);\n    const lineTokens = model.tokenization.getLineTokens(lineNumber);\n    const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n    const tokenType = lineTokens.getStandardTokenType(tokenIndex);\n    return tokenType;\n}\nexport { LineTokens, getStandardTokenTypeAtPosition };\n","import { OffsetRange } from '../core/offsetRange.js';\nclass TokenArray {\n    static create(tokenInfo) {\n        return ( new TokenArray(tokenInfo));\n    }\n    constructor(_tokenInfo) {\n        this._tokenInfo = _tokenInfo;\n    }\n    forEach(cb) {\n        let lengthSum = 0;\n        for (const tokenInfo of this._tokenInfo) {\n            const range = ( new OffsetRange(lengthSum, lengthSum + tokenInfo.length));\n            cb(range, tokenInfo);\n            lengthSum += tokenInfo.length;\n        }\n    }\n    slice(range) {\n        const result = [];\n        let lengthSum = 0;\n        for (const tokenInfo of this._tokenInfo) {\n            const tokenStart = lengthSum;\n            const tokenEndEx = tokenStart + tokenInfo.length;\n            if (tokenEndEx > range.start) {\n                if (tokenStart >= range.endExclusive) {\n                    break;\n                }\n                const deltaBefore = Math.max(0, range.start - tokenStart);\n                const deltaAfter = Math.max(0, tokenEndEx - range.endExclusive);\n                result.push(( new TokenInfo(tokenInfo.length - deltaBefore - deltaAfter, tokenInfo.metadata)));\n            }\n            lengthSum += tokenInfo.length;\n        }\n        return TokenArray.create(result);\n    }\n}\nclass TokenInfo {\n    constructor(length, metadata) {\n        this.length = length;\n        this.metadata = metadata;\n    }\n}\nclass TokenArrayBuilder {\n    constructor() {\n        this._tokens = [];\n    }\n    add(length, metadata) {\n        this._tokens.push(( new TokenInfo(length, metadata)));\n    }\n    build() {\n        return TokenArray.create(this._tokens);\n    }\n}\nexport { TokenArray, TokenArrayBuilder, TokenInfo };\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar [chunkIds, fn, priority] = deferred[i];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);\nvar leafPrototypes;\n// create a fake namespace object\n// mode & 1: value is a module id, require it\n// mode & 2: merge all properties of value into the ns\n// mode & 4: return value when already ns object\n// mode & 16: return value when it's Promise-like\n// mode & 8|1: behave like require\n__webpack_require__.t = function(value, mode) {\n\tif(mode & 1) value = this(value);\n\tif(mode & 8) return value;\n\tif(typeof value === 'object' && value) {\n\t\tif((mode & 4) && value.__esModule) return value;\n\t\tif((mode & 16) && typeof value.then === 'function') return value;\n\t}\n\tvar ns = Object.create(null);\n\t__webpack_require__.r(ns);\n\tvar def = {};\n\tleafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];\n\tfor(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {\n\t\tObject.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));\n\t}\n\tdef['default'] = () => (value);\n\t__webpack_require__.d(ns, def);\n\treturn ns;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"\" + chunkId + \".immt_editor.js\";\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t\"vendors-node_modules_codingame_monaco-vscode-textmate-service-override_worker_js\": 0\n};\n\nvar installChunk = (data) => {\n\tvar {ids, modules, runtime} = data;\n\t// add \"modules\" to the modules object,\n\t// then flag all \"ids\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tfor(moduleId in modules) {\n\t\tif(__webpack_require__.o(modules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = modules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\tfor(;i < ids.length; i++) {\n\t\tchunkId = ids[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[ids[i]] = 0;\n\t}\n\t__webpack_require__.O();\n}\n\n__webpack_require__.f.j = (chunkId, promises) => {\n\t\t// import() chunk loading for javascript\n\t\tvar installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;\n\t\tif(installedChunkData !== 0) { // 0 means \"already installed\".\n\n\t\t\t// a Promise means \"currently loading\".\n\t\t\tif(installedChunkData) {\n\t\t\t\tpromises.push(installedChunkData[1]);\n\t\t\t} else {\n\t\t\t\tif(true) { // all chunks have JS\n\t\t\t\t\t// setup Promise in chunk cache\n\t\t\t\t\tvar promise = import(\"./\" + __webpack_require__.u(chunkId)).then(installChunk, (e) => {\n\t\t\t\t\t\tif(installedChunks[chunkId] !== 0) installedChunks[chunkId] = undefined;\n\t\t\t\t\t\tthrow e;\n\t\t\t\t\t});\n\t\t\t\t\tvar promise = Promise.race([promise, new Promise((resolve) => (installedChunkData = installedChunks[chunkId] = [resolve]))])\n\t\t\t\t\tpromises.push(installedChunkData[1] = promise);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n};\n\n// no prefetching\n\n// no preloaded\n\n// no external install chunk\n\n__webpack_require__.O.j = (chunkId) => (installedChunks[chunkId] === 0);","","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [\"vendors-node_modules_vscode_vscode_src_vs_base_common_assert_js-node_modules_vscode_vscode_sr-39c9f0\",\"vendors-node_modules_vscode_vscode_src_vs_base_common_buffer_js-node_modules_vscode_vscode_sr-2c9cae\",\"vendors-node_modules_vscode_vscode_src_vs_base_common_worker_simpleWorker_js-node_modules_vsc-6729ec\",\"vendors-node_modules_codingame_monaco-vscode-textmate-service-override_vscode_src_vs_workbenc-f788c8\"], () => (__webpack_require__(\"./node_modules/@codingame/monaco-vscode-textmate-service-override/worker.js\")))\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n",""],"names":[],"sourceRoot":""}